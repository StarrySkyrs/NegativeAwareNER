{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Changing the transformers and tokenizer versions","metadata":{}},{"cell_type":"code","source":"pip install tokenizers==0.8.0rc4","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:47:16.842852Z","iopub.execute_input":"2022-05-22T21:47:16.843340Z","iopub.status.idle":"2022-05-22T21:47:28.884725Z","shell.execute_reply.started":"2022-05-22T21:47:16.843299Z","shell.execute_reply":"2022-05-22T21:47:28.883855Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tokenizers==0.8.0rc4\n  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.12.1\n    Uninstalling tokenizers-0.12.1:\n      Successfully uninstalled tokenizers-0.12.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntransformers 4.18.0 requires tokenizers!=0.11.3,<0.13,>=0.11.1, but you have tokenizers 0.8.0rc4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.8.0rc4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers==3.0.1","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:47:28.886441Z","iopub.execute_input":"2022-05-22T21:47:28.886645Z","iopub.status.idle":"2022-05-22T21:47:40.817922Z","shell.execute_reply.started":"2022-05-22T21:47:28.886618Z","shell.execute_reply":"2022-05-22T21:47:40.817040Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting transformers==3.0.1\n  Downloading transformers-3.0.1-py3-none-any.whl (757 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.2/757.2 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (4.63.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (2021.11.10)\nRequirement already satisfied: tokenizers==0.8.0-rc4 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (0.8.0rc4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (2.27.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (3.6.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (1.21.6)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (0.0.53)\nRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (0.1.96)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.1) (3.0.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (1.26.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (2.0.12)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.1) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.1) (8.0.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.1) (1.16.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers==3.0.1) (4.11.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.1) (3.7.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.1) (4.2.0)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.18.0\n    Uninstalling transformers-4.18.0:\n      Successfully uninstalled transformers-4.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.9.3 requires transformers<4.19,>=4.1, but you have transformers 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed transformers-3.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\ntransformers.__version__","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:47:40.819835Z","iopub.execute_input":"2022-05-22T21:47:40.820134Z","iopub.status.idle":"2022-05-22T21:47:49.044319Z","shell.execute_reply.started":"2022-05-22T21:47:40.820093Z","shell.execute_reply":"2022-05-22T21:47:49.043591Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The current process just got forked. Disabling parallelism to avoid deadlocks...\nTo disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\nThe current process just got forked. Disabling parallelism to avoid deadlocks...\nTo disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","output_type":"stream"},{"name":"stdout","text":"The current process just got forked. Disabling parallelism to avoid deadlocks...\nTo disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'3.0.1'"},"metadata":{}}]},{"cell_type":"code","source":"import tokenizers\ntokenizers.__version__","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:47:49.046718Z","iopub.execute_input":"2022-05-22T21:47:49.046999Z","iopub.status.idle":"2022-05-22T21:47:49.055126Z","shell.execute_reply.started":"2022-05-22T21:47:49.046959Z","shell.execute_reply":"2022-05-22T21:47:49.054035Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'0.8.0.rc4'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification,AutoConfig","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:47:52.409588Z","iopub.execute_input":"2022-05-22T21:47:52.410142Z","iopub.status.idle":"2022-05-22T21:47:52.415981Z","shell.execute_reply.started":"2022-05-22T21:47:52.410104Z","shell.execute_reply":"2022-05-22T21:47:52.415251Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Reading data","metadata":{}},{"cell_type":"code","source":"un_neg_data= pd.read_csv(\"../input/nertag/unnegated_File_Name.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:47:54.200965Z","iopub.execute_input":"2022-05-22T21:47:54.201731Z","iopub.status.idle":"2022-05-22T21:47:54.222676Z","shell.execute_reply.started":"2022-05-22T21:47:54.201686Z","shell.execute_reply":"2022-05-22T21:47:54.222032Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"un_neg_data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:47:55.958390Z","iopub.execute_input":"2022-05-22T21:47:55.958662Z","iopub.status.idle":"2022-05-22T21:47:55.977353Z","shell.execute_reply.started":"2022-05-22T21:47:55.958633Z","shell.execute_reply":"2022-05-22T21:47:55.976666Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                              Sentence  \\\n0    I am looking for a black gloss 33 inch firecla...   \n1    Looking for pre workout Pump addict instead of...   \n2    i need a 48 inch glass sliding goof and a show...   \n3    Hello, do any of your free standing tubs have ...   \n4    I'm looking for a 24 inch white mirror that is...   \n..                                                 ...   \n162       What rectangular shower units are available?   \n163  I am looking for a 35 inch bathroom sink count...   \n164  I'm looking f or a Black Matte bathtub double ...   \n165               Need a 27 inch frameless shower door   \n166                 Looking for 30 inch white desk set   \n\n                                                  Tags  \n0    O,O,O,O,O,B-COLOUR,B-TEXTURE,B-SIZE,I-SIZE,B-P...  \n1    O,O,B-PRODUCT,I-PRODUCT,I-PRODUCT,I-PRODUCT,O,...  \n2    O,O,O,B-SIZE,I-SIZE,B-MATERIAL,B-PRODUCT,I-PRO...  \n3    O,O,O,O,O,B-ATTRIBUTE,I-ATTRIBUTE,B-PRODUCT,O,...  \n4    O,O,O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,O,O,B...  \n..                                                 ...  \n162                  O,B-SHAPE,B-PRODUCT,I-PRODUCT,O,O  \n163  O,O,O,O,O,B-SIZE,I-SIZE,B-PRODUCT,I-PRODUCT,I-...  \n164  O,O,O,O,O,B-COLOUR,B-TEXTURE,B-PRODUCT,I-PRODU...  \n165  O,O,B-SIZE,I-SIZE,B-ATTRIBUTE,B-PRODUCT,I-PRODUCT  \n166     O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,I-PRODUCT  \n\n[167 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n      <td>O,O,O,O,O,B-COLOUR,B-TEXTURE,B-SIZE,I-SIZE,B-P...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Looking for pre workout Pump addict instead of...</td>\n      <td>O,O,B-PRODUCT,I-PRODUCT,I-PRODUCT,I-PRODUCT,O,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i need a 48 inch glass sliding goof and a show...</td>\n      <td>O,O,O,B-SIZE,I-SIZE,B-MATERIAL,B-PRODUCT,I-PRO...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hello, do any of your free standing tubs have ...</td>\n      <td>O,O,O,O,O,B-ATTRIBUTE,I-ATTRIBUTE,B-PRODUCT,O,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm looking for a 24 inch white mirror that is...</td>\n      <td>O,O,O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,O,O,B...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>What rectangular shower units are available?</td>\n      <td>O,B-SHAPE,B-PRODUCT,I-PRODUCT,O,O</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>I am looking for a 35 inch bathroom sink count...</td>\n      <td>O,O,O,O,O,B-SIZE,I-SIZE,B-PRODUCT,I-PRODUCT,I-...</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>I'm looking f or a Black Matte bathtub double ...</td>\n      <td>O,O,O,O,O,B-COLOUR,B-TEXTURE,B-PRODUCT,I-PRODU...</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>Need a 27 inch frameless shower door</td>\n      <td>O,O,B-SIZE,I-SIZE,B-ATTRIBUTE,B-PRODUCT,I-PRODUCT</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>Looking for 30 inch white desk set</td>\n      <td>O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,I-PRODUCT</td>\n    </tr>\n  </tbody>\n</table>\n<p>167 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ndata = pd.read_csv(\"../input/nertag/File_Name.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:23.564280Z","iopub.execute_input":"2022-05-20T15:40:23.564832Z","iopub.status.idle":"2022-05-20T15:40:23.581748Z","shell.execute_reply.started":"2022-05-20T15:40:23.564790Z","shell.execute_reply":"2022-05-20T15:40:23.581084Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:26.321495Z","iopub.execute_input":"2022-05-20T15:40:26.322055Z","iopub.status.idle":"2022-05-20T15:40:26.340441Z","shell.execute_reply.started":"2022-05-20T15:40:26.322014Z","shell.execute_reply":"2022-05-20T15:40:26.339741Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                              Sentence  \\\n0    I am looking for a black gloss 33 inch firecla...   \n1    Looking for pre workout Pump addict instead of...   \n2    i need a 48 inch glass sliding goof and a show...   \n3    Hello, do any of your free standing tubs have ...   \n4    I'm looking for a 24 inch white mirror that is...   \n..                                                 ...   \n162       What rectangular shower units are available?   \n163  I am looking for a 35 inch bathroom sink count...   \n164  I'm looking f or a Black Matte bathtub double ...   \n165               Need a 27 inch frameless shower door   \n166                 Looking for 30 inch white desk set   \n\n                                                  Tags  \n0    O,O,O,O,O,B-COLOUR,B-TEXTURE,B-SIZE,I-SIZE,B-P...  \n1    O,O,B-PRODUCT,I-PRODUCT,I-PRODUCT,I-PRODUCT,O,...  \n2    O,O,O,B-SIZE,I-SIZE,B-MATERIAL,B-PRODUCT,I-PRO...  \n3    O,O,O,O,O,B-ATTRIBUTE,I-ATTRIBUTE,B-PRODUCT,O,...  \n4    O,O,O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,O,O,B...  \n..                                                 ...  \n162                  O,B-SHAPE,B-PRODUCT,I-PRODUCT,O,O  \n163  O,O,O,O,O,B-SIZE,I-SIZE,B-PRODUCT,I-PRODUCT,I-...  \n164  O,O,O,O,O,B-COLOUR,B-TEXTURE,B-PRODUCT,I-PRODU...  \n165  O,O,B-SIZE,I-SIZE,B-N-ATTRIBUTE,B-PRODUCT,I-PR...  \n166     O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,I-PRODUCT  \n\n[167 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n      <td>O,O,O,O,O,B-COLOUR,B-TEXTURE,B-SIZE,I-SIZE,B-P...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Looking for pre workout Pump addict instead of...</td>\n      <td>O,O,B-PRODUCT,I-PRODUCT,I-PRODUCT,I-PRODUCT,O,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i need a 48 inch glass sliding goof and a show...</td>\n      <td>O,O,O,B-SIZE,I-SIZE,B-MATERIAL,B-PRODUCT,I-PRO...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hello, do any of your free standing tubs have ...</td>\n      <td>O,O,O,O,O,B-ATTRIBUTE,I-ATTRIBUTE,B-PRODUCT,O,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm looking for a 24 inch white mirror that is...</td>\n      <td>O,O,O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,O,O,B...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>What rectangular shower units are available?</td>\n      <td>O,B-SHAPE,B-PRODUCT,I-PRODUCT,O,O</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>I am looking for a 35 inch bathroom sink count...</td>\n      <td>O,O,O,O,O,B-SIZE,I-SIZE,B-PRODUCT,I-PRODUCT,I-...</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>I'm looking f or a Black Matte bathtub double ...</td>\n      <td>O,O,O,O,O,B-COLOUR,B-TEXTURE,B-PRODUCT,I-PRODU...</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>Need a 27 inch frameless shower door</td>\n      <td>O,O,B-SIZE,I-SIZE,B-N-ATTRIBUTE,B-PRODUCT,I-PR...</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>Looking for 30 inch white desk set</td>\n      <td>O,O,B-SIZE,I-SIZE,B-COLOUR,B-PRODUCT,I-PRODUCT</td>\n    </tr>\n  </tbody>\n</table>\n<p>167 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"secondary_data = pd.read_csv(\"../input/nertag/clean_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:35:34.901470Z","iopub.execute_input":"2022-05-20T16:35:34.901934Z","iopub.status.idle":"2022-05-20T16:35:34.911575Z","shell.execute_reply.started":"2022-05-20T16:35:34.901897Z","shell.execute_reply":"2022-05-20T16:35:34.910772Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data= pd.read_csv(\"../input/nertag/un-negated_clean_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:01.223849Z","iopub.execute_input":"2022-05-22T21:48:01.224270Z","iopub.status.idle":"2022-05-22T21:48:01.238792Z","shell.execute_reply.started":"2022-05-22T21:48:01.224237Z","shell.execute_reply":"2022-05-22T21:48:01.238028Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:03.585103Z","iopub.execute_input":"2022-05-22T21:48:03.585792Z","iopub.status.idle":"2022-05-22T21:48:03.598104Z","shell.execute_reply.started":"2022-05-22T21:48:03.585755Z","shell.execute_reply":"2022-05-22T21:48:03.597465Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       Tokens       Tags  is_negative  sentence\n0           I          O        False         0\n1          am          O        False         0\n2     looking          O        False         0\n3         for          O        False         0\n4           a          O        False         0\n...       ...        ...          ...       ...\n2345       30     B-SIZE        False       166\n2346     inch     I-SIZE        False       166\n2347    white   B-COLOUR        False       166\n2348     desk  B-PRODUCT        False       166\n2349      set  I-PRODUCT        False       166\n\n[2350 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tokens</th>\n      <th>Tags</th>\n      <th>is_negative</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I</td>\n      <td>O</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>am</td>\n      <td>O</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>looking</td>\n      <td>O</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>for</td>\n      <td>O</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a</td>\n      <td>O</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2345</th>\n      <td>30</td>\n      <td>B-SIZE</td>\n      <td>False</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2346</th>\n      <td>inch</td>\n      <td>I-SIZE</td>\n      <td>False</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2347</th>\n      <td>white</td>\n      <td>B-COLOUR</td>\n      <td>False</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>desk</td>\n      <td>B-PRODUCT</td>\n      <td>False</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2349</th>\n      <td>set</td>\n      <td>I-PRODUCT</td>\n      <td>False</td>\n      <td>166</td>\n    </tr>\n  </tbody>\n</table>\n<p>2350 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"unneg_secondary_data['Sentence']= unneg_secondary_data[['sentence','Tokens','is_negative']].groupby(['sentence'])['Tokens'].transform(lambda x: ' '.join(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:06.046696Z","iopub.execute_input":"2022-05-22T21:48:06.047264Z","iopub.status.idle":"2022-05-22T21:48:06.092877Z","shell.execute_reply.started":"2022-05-22T21:48:06.047215Z","shell.execute_reply":"2022-05-22T21:48:06.092220Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data['is_negative'] = unneg_secondary_data['is_negative'].map({True: 'True', False: 'False'})","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:07.446300Z","iopub.execute_input":"2022-05-22T21:48:07.446872Z","iopub.status.idle":"2022-05-22T21:48:07.452334Z","shell.execute_reply.started":"2022-05-22T21:48:07.446834Z","shell.execute_reply":"2022-05-22T21:48:07.451598Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data['is_negative']= unneg_secondary_data[['sentence','Tokens','is_negative']].groupby(['sentence'])['is_negative'].transform(lambda x: ','.join(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:09.482793Z","iopub.execute_input":"2022-05-22T21:48:09.483333Z","iopub.status.idle":"2022-05-22T21:48:09.506631Z","shell.execute_reply.started":"2022-05-22T21:48:09.483295Z","shell.execute_reply":"2022-05-22T21:48:09.505949Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:12.066257Z","iopub.execute_input":"2022-05-22T21:48:12.066851Z","iopub.status.idle":"2022-05-22T21:48:12.083320Z","shell.execute_reply.started":"2022-05-22T21:48:12.066797Z","shell.execute_reply":"2022-05-22T21:48:12.082409Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"       Tokens       Tags                                        is_negative  \\\n0           I          O  False,False,False,False,False,False,False,Fals...   \n1          am          O  False,False,False,False,False,False,False,Fals...   \n2     looking          O  False,False,False,False,False,False,False,Fals...   \n3         for          O  False,False,False,False,False,False,False,Fals...   \n4           a          O  False,False,False,False,False,False,False,Fals...   \n...       ...        ...                                                ...   \n2345       30     B-SIZE          False,False,False,False,False,False,False   \n2346     inch     I-SIZE          False,False,False,False,False,False,False   \n2347    white   B-COLOUR          False,False,False,False,False,False,False   \n2348     desk  B-PRODUCT          False,False,False,False,False,False,False   \n2349      set  I-PRODUCT          False,False,False,False,False,False,False   \n\n      sentence                                           Sentence  \n0            0  I am looking for a black gloss 33 inch firecla...  \n1            0  I am looking for a black gloss 33 inch firecla...  \n2            0  I am looking for a black gloss 33 inch firecla...  \n3            0  I am looking for a black gloss 33 inch firecla...  \n4            0  I am looking for a black gloss 33 inch firecla...  \n...        ...                                                ...  \n2345       166                 Looking for 30 inch white desk set  \n2346       166                 Looking for 30 inch white desk set  \n2347       166                 Looking for 30 inch white desk set  \n2348       166                 Looking for 30 inch white desk set  \n2349       166                 Looking for 30 inch white desk set  \n\n[2350 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tokens</th>\n      <th>Tags</th>\n      <th>is_negative</th>\n      <th>sentence</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I</td>\n      <td>O</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n      <td>0</td>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>am</td>\n      <td>O</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n      <td>0</td>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>looking</td>\n      <td>O</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n      <td>0</td>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>for</td>\n      <td>O</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n      <td>0</td>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a</td>\n      <td>O</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n      <td>0</td>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2345</th>\n      <td>30</td>\n      <td>B-SIZE</td>\n      <td>False,False,False,False,False,False,False</td>\n      <td>166</td>\n      <td>Looking for 30 inch white desk set</td>\n    </tr>\n    <tr>\n      <th>2346</th>\n      <td>inch</td>\n      <td>I-SIZE</td>\n      <td>False,False,False,False,False,False,False</td>\n      <td>166</td>\n      <td>Looking for 30 inch white desk set</td>\n    </tr>\n    <tr>\n      <th>2347</th>\n      <td>white</td>\n      <td>B-COLOUR</td>\n      <td>False,False,False,False,False,False,False</td>\n      <td>166</td>\n      <td>Looking for 30 inch white desk set</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>desk</td>\n      <td>B-PRODUCT</td>\n      <td>False,False,False,False,False,False,False</td>\n      <td>166</td>\n      <td>Looking for 30 inch white desk set</td>\n    </tr>\n    <tr>\n      <th>2349</th>\n      <td>set</td>\n      <td>I-PRODUCT</td>\n      <td>False,False,False,False,False,False,False</td>\n      <td>166</td>\n      <td>Looking for 30 inch white desk set</td>\n    </tr>\n  </tbody>\n</table>\n<p>2350 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"unneg_secondary_data = unneg_secondary_data[['Sentence','is_negative']]","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:15.365751Z","iopub.execute_input":"2022-05-22T21:48:15.366040Z","iopub.status.idle":"2022-05-22T21:48:15.371904Z","shell.execute_reply.started":"2022-05-22T21:48:15.366008Z","shell.execute_reply":"2022-05-22T21:48:15.371175Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data = unneg_secondary_data.drop_duplicates().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:18.254538Z","iopub.execute_input":"2022-05-22T21:48:18.254800Z","iopub.status.idle":"2022-05-22T21:48:18.262683Z","shell.execute_reply.started":"2022-05-22T21:48:18.254770Z","shell.execute_reply":"2022-05-22T21:48:18.261911Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:25.063092Z","iopub.execute_input":"2022-05-22T21:48:25.063702Z","iopub.status.idle":"2022-05-22T21:48:25.077769Z","shell.execute_reply.started":"2022-05-22T21:48:25.063660Z","shell.execute_reply":"2022-05-22T21:48:25.076225Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                              Sentence  \\\n0    I am looking for a black gloss 33 inch firecla...   \n1    Looking for pre workout Pump addict instead of...   \n2    i need a 48 inch glass sliding goof and a show...   \n3    Hello, do any of your free standing tubs have ...   \n4    I'm looking for a 24 inch white mirror that is...   \n..                                                 ...   \n162       What rectangular shower units are available?   \n163  I am looking for a 35 inch bathroom sink count...   \n164  I'm looking f or a Black Matte bathtub double ...   \n165               Need a 27 inch frameless shower door   \n166                 Looking for 30 inch white desk set   \n\n                                           is_negative  \n0    False,False,False,False,False,False,False,Fals...  \n1    False,False,False,False,False,False,False,Fals...  \n2    False,False,False,False,False,False,False,Fals...  \n3    False,False,False,False,False,False,False,Fals...  \n4    False,False,False,False,False,False,False,Fals...  \n..                                                 ...  \n162                False,False,False,False,False,False  \n163  False,False,False,False,False,False,False,Fals...  \n164  False,False,False,False,False,False,False,Fals...  \n165          False,False,False,False,False,False,False  \n166          False,False,False,False,False,False,False  \n\n[167 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>is_negative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am looking for a black gloss 33 inch firecla...</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Looking for pre workout Pump addict instead of...</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i need a 48 inch glass sliding goof and a show...</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hello, do any of your free standing tubs have ...</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm looking for a 24 inch white mirror that is...</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>What rectangular shower units are available?</td>\n      <td>False,False,False,False,False,False</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>I am looking for a 35 inch bathroom sink count...</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>I'm looking f or a Black Matte bathtub double ...</td>\n      <td>False,False,False,False,False,False,False,Fals...</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>Need a 27 inch frameless shower door</td>\n      <td>False,False,False,False,False,False,False</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>Looking for 30 inch white desk set</td>\n      <td>False,False,False,False,False,False,False</td>\n    </tr>\n  </tbody>\n</table>\n<p>167 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"unneg_secondary_data.to_csv(r'./unnegated_Fil.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:31.525533Z","iopub.execute_input":"2022-05-22T21:48:31.526304Z","iopub.status.idle":"2022-05-22T21:48:31.535158Z","shell.execute_reply.started":"2022-05-22T21:48:31.526254Z","shell.execute_reply":"2022-05-22T21:48:31.534438Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"secondary_data","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:33.649702Z","iopub.execute_input":"2022-05-20T15:40:33.650416Z","iopub.status.idle":"2022-05-20T15:40:33.660909Z","shell.execute_reply.started":"2022-05-20T15:40:33.650374Z","shell.execute_reply":"2022-05-20T15:40:33.660224Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"       Tokens       Tags  sentence\n0           I          O         0\n1          am          O         0\n2     looking          O         0\n3         for          O         0\n4           a          O         0\n...       ...        ...       ...\n2345       30     B-SIZE       166\n2346     inch     I-SIZE       166\n2347    white   B-COLOUR       166\n2348     desk  B-PRODUCT       166\n2349      set  I-PRODUCT       166\n\n[2350 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tokens</th>\n      <th>Tags</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>am</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>looking</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>for</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2345</th>\n      <td>30</td>\n      <td>B-SIZE</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2346</th>\n      <td>inch</td>\n      <td>I-SIZE</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2347</th>\n      <td>white</td>\n      <td>B-COLOUR</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>desk</td>\n      <td>B-PRODUCT</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>2349</th>\n      <td>set</td>\n      <td>I-PRODUCT</td>\n      <td>166</td>\n    </tr>\n  </tbody>\n</table>\n<p>2350 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"labels_to_ids = {k: v for v, k in enumerate(unneg_secondary_data.Tags.unique())}\nids_to_labels = {v: k for v, k in enumerate(unneg_secondary_data.Tags.unique())}\nlabels_to_ids","metadata":{"execution":{"iopub.status.busy":"2022-05-22T04:09:45.658649Z","iopub.execute_input":"2022-05-22T04:09:45.659200Z","iopub.status.idle":"2022-05-22T04:09:45.689409Z","shell.execute_reply.started":"2022-05-22T04:09:45.659164Z","shell.execute_reply":"2022-05-22T04:09:45.688510Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1994088811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_to_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munneg_secondary_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mids_to_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munneg_secondary_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels_to_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Tags'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'Tags'","output_type":"error"}]},{"cell_type":"code","source":"labels_to_ids = {'True':1,'False':0}\nids_to_labels = {1: 'True', 0: 'False'}","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:42.893145Z","iopub.execute_input":"2022-05-22T21:48:42.893641Z","iopub.status.idle":"2022-05-22T21:48:42.897544Z","shell.execute_reply.started":"2022-05-22T21:48:42.893603Z","shell.execute_reply":"2022-05-22T21:48:42.896544Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128\nTRAIN_BATCH_SIZE = 128\nVALID_BATCH_SIZE = 2\nEPOCHS = 1\nLEARNING_RATE = 1e-05\nMAX_GRAD_NORM = 10\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:48:45.587391Z","iopub.execute_input":"2022-05-22T21:48:45.588095Z","iopub.status.idle":"2022-05-22T21:48:46.577544Z","shell.execute_reply.started":"2022-05-22T21:48:45.588061Z","shell.execute_reply":"2022-05-22T21:48:46.576815Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abead5831ae54c389539f093761ccdf6"}},"metadata":{}}]},{"cell_type":"code","source":"class dataset(Dataset):\n  def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n  def __getitem__(self, index):\n        # step 1: get the sentence and word labels \n        sentence = self.data.Sentence[index].strip().split()  \n        word_labels = self.data.is_negative[index].split(\",\") \n\n        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n        encoding = self.tokenizer(sentence,\n                             is_pretokenized=True, \n                             return_offsets_mapping=True, \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len)\n        \n        # step 3: create token labels only for first word pieces of each tokenized word\n        labels = [labels_to_ids[label] for label in word_labels] \n        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n        # create an empty array of -100 of length max_length\n        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n        \n        # set only labels whose first offset position is 0 and the second is not 0\n        i = 0\n        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n          if mapping[0] == 0 and mapping[1] != 0:\n            # overwrite label\n            encoded_labels[idx] = labels[i]\n            i += 1\n\n        # step 4: turn everything into PyTorch tensors\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n        item['labels'] = torch.as_tensor(encoded_labels)\n        \n        return item\n\n  def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:49:37.239539Z","iopub.execute_input":"2022-05-22T21:49:37.239833Z","iopub.status.idle":"2022-05-22T21:49:37.252783Z","shell.execute_reply.started":"2022-05-22T21:49:37.239800Z","shell.execute_reply":"2022-05-22T21:49:37.251952Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\",use_fast=True)\n# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:31:26.293785Z","iopub.execute_input":"2022-05-16T15:31:26.294571Z","iopub.status.idle":"2022-05-16T15:31:30.658826Z","shell.execute_reply.started":"2022-05-16T15:31:26.294521Z","shell.execute_reply":"2022-05-16T15:31:30.658113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_dataset = unneg_secondary_data.sample(frac=train_size,random_state=200)\ntest_dataset = unneg_secondary_data.drop(train_dataset.index).reset_index(drop=True)\ntrain_dataset = train_dataset.reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(unneg_secondary_data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = dataset(train_dataset, tokenizer, MAX_LEN)\ntesting_set = dataset(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:49:41.900658Z","iopub.execute_input":"2022-05-22T21:49:41.901384Z","iopub.status.idle":"2022-05-22T21:49:41.910706Z","shell.execute_reply.started":"2022-05-22T21:49:41.901337Z","shell.execute_reply":"2022-05-22T21:49:41.909667Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"FULL Dataset: (167, 2)\nTRAIN Dataset: (134, 2)\nTEST Dataset: (33, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:49:44.350272Z","iopub.execute_input":"2022-05-22T21:49:44.350918Z","iopub.status.idle":"2022-05-22T21:49:44.367712Z","shell.execute_reply.started":"2022-05-22T21:49:44.350881Z","shell.execute_reply":"2022-05-22T21:49:44.366908Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  101,  1045,  2215,  2074,  2023,  5239,  2302,  1996,  2327,  2004,\n          1045,  2215,  2327,  5614, 22739,  2006,  1037,  3302,  9844,  2026,\n          3829,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0]),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'offset_mapping': tensor([[0, 0],\n         [0, 1],\n         [0, 4],\n         [0, 4],\n         [0, 4],\n         [0, 7],\n         [0, 7],\n         [0, 3],\n         [0, 3],\n         [0, 2],\n         [0, 1],\n         [0, 4],\n         [0, 3],\n         [0, 7],\n         [0, 6],\n         [0, 2],\n         [0, 1],\n         [0, 7],\n         [0, 8],\n         [0, 2],\n         [0, 7],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0],\n         [0, 0]]),\n 'labels': tensor([-100,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100])}"},"metadata":{}}]},{"cell_type":"code","source":"for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n  print('{0:10}  {1}'.format(token, label))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:50:05.748787Z","iopub.execute_input":"2022-05-22T21:50:05.749051Z","iopub.status.idle":"2022-05-22T21:50:05.774728Z","shell.execute_reply.started":"2022-05-22T21:50:05.749021Z","shell.execute_reply":"2022-05-22T21:50:05.768984Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[CLS]       -100\ni           0\nwant        0\njust        0\nthis        0\ncabinet     0\nwithout     0\nthe         0\ntop         1\nas          0\ni           0\nwant        0\ntop         0\nmounted     0\nbasins      0\non          0\na           0\nsurface     0\nmatching    0\nmy          0\nkitchen     0\n[SEP]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n[PAD]       -100\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:50:12.570486Z","iopub.execute_input":"2022-05-22T21:50:12.571027Z","iopub.status.idle":"2022-05-22T21:50:12.575822Z","shell.execute_reply.started":"2022-05-22T21:50:12.570988Z","shell.execute_reply":"2022-05-22T21:50:12.575136Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:50:15.015820Z","iopub.execute_input":"2022-05-22T21:50:15.016383Z","iopub.status.idle":"2022-05-22T21:50:15.074791Z","shell.execute_reply.started":"2022-05-22T21:50:15.016342Z","shell.execute_reply":"2022-05-22T21:50:15.074067Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model Generation","metadata":{}},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:51:25.909871Z","iopub.execute_input":"2022-05-22T21:51:25.910515Z","iopub.status.idle":"2022-05-22T21:51:29.711267Z","shell.execute_reply.started":"2022-05-22T21:51:25.910477Z","shell.execute_reply":"2022-05-22T21:51:29.710488Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# from transformers import BertForSequenceClassification, BertConfig\n\n# config = AutoConfig.from_pretrained(\"dslim/bert-base-NER\")\n# config.num_labels = 28\n# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\", config =config)\n# model.parameters","metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:43:33.058849Z","iopub.execute_input":"2022-05-16T15:43:33.059178Z","iopub.status.idle":"2022-05-16T15:43:36.625781Z","shell.execute_reply.started":"2022-05-16T15:43:33.059146Z","shell.execute_reply":"2022-05-16T15:43:36.624777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = training_set[2]\ninput_ids = inputs[\"input_ids\"].unsqueeze(0)\nattention_mask = inputs[\"attention_mask\"].unsqueeze(0)\nlabels = inputs[\"labels\"].unsqueeze(0)\n\ninput_ids = input_ids.to(device)\nattention_mask = attention_mask.to(device)\nlabels = labels.to(device)\n\noutputs = model(input_ids, attention_mask=attention_mask, labels=labels)\ninitial_loss = outputs[0]\ninitial_loss","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:51:39.275994Z","iopub.execute_input":"2022-05-22T21:51:39.276295Z","iopub.status.idle":"2022-05-22T21:51:39.303651Z","shell.execute_reply.started":"2022-05-22T21:51:39.276261Z","shell.execute_reply":"2022-05-22T21:51:39.302922Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"tensor(0.6111, device='cuda:0', grad_fn=<NllLossBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"tr_logits = outputs[1]\ntr_logits.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:51:41.622648Z","iopub.execute_input":"2022-05-22T21:51:41.623230Z","iopub.status.idle":"2022-05-22T21:51:41.629257Z","shell.execute_reply.started":"2022-05-22T21:51:41.623172Z","shell.execute_reply":"2022-05-22T21:51:41.628111Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 128, 2])"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:51:44.715535Z","iopub.execute_input":"2022-05-22T21:51:44.716270Z","iopub.status.idle":"2022-05-22T21:51:44.721383Z","shell.execute_reply.started":"2022-05-22T21:51:44.716220Z","shell.execute_reply":"2022-05-22T21:51:44.720568Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\ndef train(epoch):\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    tr_preds, tr_labels = [], []\n    # put model in training mode\n    model.train()\n    \n    for idx, batch in enumerate(training_loader):\n        \n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        labels = batch['labels'].to(device, dtype = torch.long)\n\n        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n        \n        if idx % 100==0:\n            loss_step = tr_loss/nb_tr_steps\n            print(f\"Training loss per 100 training steps: {loss_step}\")\n           \n        # compute training accuracy\n        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n        \n        # only compute accuracy at active labels\n        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n        \n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        \n        tr_labels.extend(labels)\n        tr_preds.extend(predictions)\n\n        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n        tr_accuracy += tmp_tr_accuracy\n    \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:51:46.895943Z","iopub.execute_input":"2022-05-22T21:51:46.896221Z","iopub.status.idle":"2022-05-22T21:51:46.910821Z","shell.execute_reply.started":"2022-05-22T21:51:46.896170Z","shell.execute_reply":"2022-05-22T21:51:46.908834Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    print(f\"Training epoch: {epoch + 1}\")\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:51:54.273562Z","iopub.execute_input":"2022-05-22T21:51:54.273826Z","iopub.status.idle":"2022-05-22T21:51:55.847698Z","shell.execute_reply.started":"2022-05-22T21:51:54.273796Z","shell.execute_reply":"2022-05-22T21:51:55.846860Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Training epoch: 1\nTraining loss per 100 training steps: 0.6267070174217224\nTraining loss epoch: 0.5953530967235565\nTraining accuracy epoch: 0.7660238770585496\n","output_type":"stream"}]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    # put model in evaluation mode\n    model.eval()\n    \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_examples, nb_eval_steps = 0, 0\n    eval_preds, eval_labels = [], []\n    \n    with torch.no_grad():\n        for idx, batch in enumerate(testing_loader):\n            \n            ids = batch['input_ids'].to(device, dtype = torch.long)\n            mask = batch['attention_mask'].to(device, dtype = torch.long)\n            labels = batch['labels'].to(device, dtype = torch.long)\n            \n            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n            \n            eval_loss += loss.item()\n\n            nb_eval_steps += 1\n            nb_eval_examples += labels.size(0)\n        \n            if idx % 100==0:\n                loss_step = eval_loss/nb_eval_steps\n                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n              \n            # compute evaluation accuracy\n            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n            \n            # only compute accuracy at active labels\n            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        \n            labels = torch.masked_select(flattened_targets, active_accuracy)\n            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n            \n            eval_labels.extend(labels)\n            eval_preds.extend(predictions)\n            \n            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n            eval_accuracy += tmp_eval_accuracy\n\n    labels = [ids_to_labels[id.item()] for id in eval_labels]\n    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n    \n    eval_loss = eval_loss / nb_eval_steps\n    eval_accuracy = eval_accuracy / nb_eval_steps\n    print(f\"Validation Loss: {eval_loss}\")\n    print(f\"Validation Accuracy: {eval_accuracy}\")\n\n    return labels, predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:52:03.405778Z","iopub.execute_input":"2022-05-22T21:52:03.406040Z","iopub.status.idle":"2022-05-22T21:52:03.418269Z","shell.execute_reply.started":"2022-05-22T21:52:03.406009Z","shell.execute_reply":"2022-05-22T21:52:03.417133Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"labels, predictions = valid(model, testing_loader)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:52:07.127816Z","iopub.execute_input":"2022-05-22T21:52:07.128087Z","iopub.status.idle":"2022-05-22T21:52:07.370413Z","shell.execute_reply.started":"2022-05-22T21:52:07.128056Z","shell.execute_reply":"2022-05-22T21:52:07.369231Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Validation loss per 100 evaluation steps: 0.4822540879249573\nValidation Loss: 0.4697296777192284\nValidation Accuracy: 0.930022945139386\n","output_type":"stream"}]},{"cell_type":"code","source":"# from seqeval.metrics import classification_report\nfrom sklearn.metrics import f1_score, classification_report\n\nprint(classification_report(labels, predictions, labels = list(labels_to_ids.keys()) ))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:52:24.485534Z","iopub.execute_input":"2022-05-22T21:52:24.485818Z","iopub.status.idle":"2022-05-22T21:52:24.504179Z","shell.execute_reply.started":"2022-05-22T21:52:24.485787Z","shell.execute_reply":"2022-05-22T21:52:24.503379Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        True       0.20      0.04      0.06        26\n       False       0.95      0.99      0.97       451\n\n    accuracy                           0.94       477\n   macro avg       0.57      0.51      0.52       477\nweighted avg       0.91      0.94      0.92       477\n\n","output_type":"stream"}]}]}