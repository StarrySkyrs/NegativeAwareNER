{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e93d43-0cd8-4678-93f0-6503a9eb5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c20571-9315-4e47-a690-07d67e601713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (60.5.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\miniconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\andre\\miniconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "âœ” Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\andre\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\andre\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\andre\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\andre\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\andre\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\andre\\miniconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec5ed181-378b-4533-9e92-8d0c0677abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013552a7-6734-4fc8-8383-191d496b0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/ner_tagged.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad220f8-ebed-4eaf-b434-0d202f4b045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'O':'Tags','-DOCSTART-':'Tokens','-X-':'X'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0e7e76-0723-4466-9bb8-078937693787",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in data.reset_index().iterrows():\n",
    "    if type(row.Tokens) == str:\n",
    "        if row.Tokens.lower().startswith(\"un\") and \"-N-\" in row.Tags and row.Tokens != \"undermounted\":\n",
    "            data.at[i,'Tags'] = row.Tags.replace(\"N-\", \"\")\n",
    "    if type(row.Tokens) == str:\n",
    "        if row.Tokens.lower().endswith(\"less\") or row.Tokens.lower().endswith(\"less.\") and row.Tokens.lower() not in [\"screw\", \"less\"] and \"-N-\" in row.Tags:\n",
    "            data.at[i,'Tags'] = row.Tags.replace(\"N-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2ff45b-b61a-4763-82be-121dded04bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "is_negative = []\n",
    "for i, row in data.reset_index().iterrows():\n",
    "    if type(row.Tokens) == str:\n",
    "        if \"-N-\" in row.Tags:\n",
    "            is_negative.append(True)\n",
    "            data.at[i, \"Tags\"] = row.Tags.replace(\"N-\", \"\")\n",
    "        else:\n",
    "            is_negative.append(False)\n",
    "    else:\n",
    "        is_negative.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "694343e3-188b-4813-bcdc-5e93967bba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"is_negative\"] = is_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6caf07ea-2289-4853-9d27-92c83e05a05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_triples(df):\n",
    "    \n",
    "    current_sent = []\n",
    "    \n",
    "    all_sents = []\n",
    "    \n",
    "    for i, row in df.reset_index().iterrows():\n",
    "        if type(row.Tags) == str:\n",
    "            current_sent.append((row.Tokens, row.Tags, row.is_negative))\n",
    "        else:\n",
    "            all_sents.append(current_sent)\n",
    "            current_sent = []\n",
    "            \n",
    "    return(all_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "169bb733-8606-45e1-8ccd-c2848de4ae6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_sents = get_triples(data)\n",
    "\n",
    "neg_sents = []\n",
    "\n",
    "for sent in all_sents:\n",
    "    for word, iob, neg in sent:\n",
    "        if neg == True:\n",
    "            neg_sents.append(sent)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627c8c59-1bbc-45f2-9bcd-70073fdbe7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sentence(sent, for_evaluation=False):\n",
    "    \n",
    "    list_counter = 0\n",
    "\n",
    "    final_list = []\n",
    "\n",
    "    current_list = []\n",
    "\n",
    "    entity_indices = []\n",
    "    \n",
    "    pos_indices = []\n",
    "    \n",
    "    neg_indices = []\n",
    "    \n",
    "    pos_ent_names = []\n",
    "    \n",
    "    neg_ent_names = []\n",
    "\n",
    "    for i in range(1, len(sent)):\n",
    "        first_word = sent[i-1][0]\n",
    "        first_iob = sent[i-1][1][0]\n",
    "        second_word = sent[i][0]\n",
    "        second_iob = sent[i][1][0]\n",
    "        if for_evaluation:\n",
    "            first_neg = sent[i-1][2]\n",
    "            second_neg = sent[i][2]\n",
    "\n",
    "        if len(current_list) == 0:\n",
    "            current_list.append(first_word)\n",
    "\n",
    "        if (first_iob == second_iob or second_iob == \"I\") and second_iob != \"B\":\n",
    "            current_list.append(second_word)\n",
    "\n",
    "        else:\n",
    "            if first_iob != \"O\":\n",
    "                entity_indices.append(list_counter)\n",
    "                if for_evaluation:\n",
    "                    if first_neg == True:\n",
    "                        neg_indices.append(list_counter)\n",
    "                    else:\n",
    "                        pos_indices.append(list_counter)\n",
    "\n",
    "            final_list.append(current_list)\n",
    "            current_list = []\n",
    "            list_counter += 1\n",
    "\n",
    "            if i == len(sent)-1:\n",
    "                final_list.append([second_word])\n",
    "                if second_iob == \"B\":\n",
    "                    entity_indices.append(list_counter)\n",
    "                    if for_evaluation:\n",
    "                        if second_neg == True:\n",
    "                            neg_indices.append(list_counter)\n",
    "                        else:\n",
    "                            pos_indices.append(list_counter)\n",
    "\n",
    "    if current_list != [] and second_iob == \"I\":\n",
    "        final_list.append(current_list)\n",
    "        entity_indices.append(list_counter)\n",
    "        if for_evaluation:\n",
    "            if second_neg == True:\n",
    "                neg_indices.append(list_counter)\n",
    "            else:\n",
    "                pos_indices.append(list_counter)\n",
    "        \n",
    "    if for_evaluation:\n",
    "        for ent_idx in pos_indices:\n",
    "            for i, phrase in enumerate(final_list):\n",
    "                if i == ent_idx:\n",
    "                    pos_ent_names.append(\" \".join(word for word in final_list[i]))\n",
    "\n",
    "        for ent_idx in neg_indices:\n",
    "            for i, phrase in enumerate(final_list):\n",
    "                if i == ent_idx:\n",
    "                    neg_ent_names.append(\" \".join(word for word in final_list[i]))\n",
    "                    \n",
    "        return pos_ent_names, neg_ent_names\n",
    "    \n",
    "    else:\n",
    "        return final_list, entity_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0baccf7a-8fba-4f84-b438-6e32940a19d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['soft', 'Open face', 'cardigan'], ['buttons.'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_sentence(neg_sents[3], for_evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367b03ac-f9d4-4779-a606-9dc550785cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gold_data(sent_list, output_style=\"tags\", word_of_interest=None):\n",
    "    \n",
    "    if word_of_interest:\n",
    "        active_list = []\n",
    "        for sent in sent_list:\n",
    "            for word, iob, tag in sent:\n",
    "                if word.lower() == word_of_interest:\n",
    "                    active_list.append(sent)\n",
    "                    break\n",
    "    \n",
    "    else:\n",
    "        active_list = sent_list\n",
    "    \n",
    "    if output_style == \"tags\":\n",
    "        outputs = []\n",
    "        for sent in active_list:\n",
    "            out = []\n",
    "            for word, iob, neg in sent:\n",
    "                out.append(neg)\n",
    "            outputs.append(out)\n",
    "        return outputs\n",
    "    \n",
    "    elif output_style == \"entities\":\n",
    "        pos_ents = []\n",
    "        neg_ents = []\n",
    "        \n",
    "        for sent in active_list:\n",
    "            sent_pos_ents, sent_neg_ents = transform_sentence(sent, for_evaluation=True)\n",
    "            pos_ents.append(sent_pos_ents)\n",
    "            neg_ents.append(sent_neg_ents)\n",
    "            \n",
    "        return pos_ents, neg_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "094239c3-9cc9-416b-80be-38fa34c2a08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pre workout Pump addict'], ['free standing', 'tubs', 'matte', 'white'], ['throw blankets.', 'Boucle wool-like', 'throw', 'soft.', 'wool-like', 'soft', 'blanket'], ['soft', 'Open face', 'cardigan'], ['oval', 'tubs', 'matte', 'white', 'higher prices.'], ['vanity tops', 'wall mount', 'sink'], ['60\" wide', 'tub', 'soaker type', 'deeper'], ['pure white', 'alcove', 'bathtub,', 'American standard'], ['navy', 'mirror', '60x31.', 'navy.'], ['floating', 'vanity', 'integrated sink', 'counter top', 'faucet', 'faucets', 'wall mounted.']]\n",
      "[['Karbolyn Hydrate'], ['glossy'], ['scratchy.'], ['buttons.'], ['gloss?'], ['faucet holes?'], ['regular tub'], ['off whites.'], ['gold', 'black'], ['drill holes']]\n"
     ]
    }
   ],
   "source": [
    "print(prepare_gold_data(neg_sents, output_style=\"entities\")[0][:10])\n",
    "print(prepare_gold_data(neg_sents, output_style=\"entities\")[1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85e438f-0640-42f1-98d6-f95f802348e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(preds, gold, input_style=\"tags\"):\n",
    "    \n",
    "    total = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    if input_style == \"tags\":\n",
    "        for i, pred in enumerate(preds):\n",
    "            for j, tag in enumerate(pred):\n",
    "                total += 1\n",
    "                if tag == True and gold[i][j] == True:\n",
    "                    true_pos += 1\n",
    "                elif tag == True and gold[i][j] == False:\n",
    "                    false_pos += 1\n",
    "                elif tag == False and gold[i][j] == True:\n",
    "                    false_neg += 1\n",
    "                elif tag == False and gold[i][j] == False:\n",
    "                    true_neg += 1\n",
    "                \n",
    "    if input_style == \"entities\":\n",
    "        pred_pos_ents = preds[0]\n",
    "        pred_neg_ents = preds[1]\n",
    "        gold_pos_ents = gold[0]\n",
    "        gold_neg_ents = gold[1]\n",
    "        \n",
    "        for i in range(len(pred_pos_ents)):\n",
    "            for ent in pred_pos_ents[i]:\n",
    "                total += 1\n",
    "                if ent in gold_pos_ents[i]:\n",
    "                    true_pos += 1\n",
    "                    gold_pos_ents[i].remove(ent)\n",
    "                else:\n",
    "                    false_pos += 1\n",
    "            for ent in pred_neg_ents[i]:\n",
    "                total += 1\n",
    "                if ent in gold_pos_ents[i]:\n",
    "                    false_neg += 1\n",
    "                    gold_neg_ents[i].remove(ent)\n",
    "                else:\n",
    "                    true_neg += 1\n",
    "                    \n",
    "    correct = true_pos + true_neg\n",
    "    accuracy = correct / total\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    print(\"Evaluation config:\", input_style)\n",
    "    print(\"Accuracy:\", \"{:.0%}\".format(accuracy))\n",
    "    print(\"Precision:\", '{:.0%}'.format(precision))\n",
    "    print(\"Recall:\", '{:.0%}'.format(recall))\n",
    "    print(\"F1:\", '{:.0%}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96088bf7-03fd-4531-ad9f-a17155661224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "def get_spacy_tokens(transformed_sent, entity_indices):\n",
    "    \"\"\"Maps entity indices to indices in a spacy object.\"\"\"\n",
    "    \n",
    "    ent_2_spacy = {}\n",
    "    string_sent = \" \".join([item for sublist in transformed_sent for item in sublist])\n",
    "    doc = nlp(string_sent)\n",
    "    \n",
    "    spacy_special = [\"'\", '\"', \":\", \";\", \",\", \"?\", \"!\", \".\", \"n't\", \"'m\"]\n",
    "    \n",
    "    for ent_idx in entity_indices:\n",
    "        substring = \" \".join([item for item in transformed_sent[ent_idx]])\n",
    "        for char in spacy_special:\n",
    "            if substring.endswith(char):\n",
    "                substring = substring[:-len(char)]\n",
    "        \n",
    "        if str(doc).count(substring) == 1:\n",
    "            end = str(doc).index(substring) + len(substring)\n",
    "            start = end - len(substring.split()[-1])\n",
    "            span = doc.char_span(start, end)[0]\n",
    "            index = span.i\n",
    "\n",
    "        elif str(doc).count(substring) > 1:\n",
    "            best_guess_distance = 10000\n",
    "            original = len(\" \".join([item for sublist in transformed_sent[:ent_idx] for item in sublist])) + 1\n",
    "            for idx in [_.start() for _ in re.finditer(substring, string_sent)]:\n",
    "                if abs(idx - original) < best_guess_distance:\n",
    "                    best_guess_distance = abs(idx - original)\n",
    "                    best_guess = idx\n",
    "            end = best_guess + len(substring)\n",
    "            start = end - len(substring.split()[-1])\n",
    "            span = doc.char_span(start, end)[0]\n",
    "            index = span.i\n",
    "        \n",
    "        ent_2_spacy[ent_idx] = index\n",
    "        \n",
    "    return ent_2_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b36081a-51a0-4964-9ca3-6fdf60f680f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_sentence(sent, negators, output_style=\"tags\", word_of_interest=None):\n",
    "    \n",
    "    if len(sent[0]) == 3:\n",
    "        active_sent = []\n",
    "        for word, iob, neg in sent:\n",
    "            active_sent.append((word, iob))\n",
    "            \n",
    "    if word_of_interest == None:\n",
    "        found = True\n",
    "            \n",
    "    else:\n",
    "        found = False\n",
    "        \n",
    "    for word, iob in active_sent:\n",
    "        if word.lower() == word_of_interest:\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if found:\n",
    "        \n",
    "        transformed_sent, entity_indices = transform_sentence(sent)\n",
    "\n",
    "        spacy_mapping = get_spacy_tokens(transformed_sent, entity_indices)\n",
    "\n",
    "        if output_style == \"tags\":\n",
    "            out = [0] * len(sent)\n",
    "            for negator in negators:\n",
    "                neg_indices = negator(transformed_sent, spacy_mapping, output_style)\n",
    "                for idx in neg_indices:\n",
    "                    out[idx] += 1\n",
    "\n",
    "            for i, tag in enumerate(out):\n",
    "                if tag % 2 == 0:\n",
    "                    out[i] = False\n",
    "                else:\n",
    "                    out[i] = True\n",
    "\n",
    "            return out\n",
    "\n",
    "        if output_style == \"entities\":\n",
    "            pos_ents = []\n",
    "            neg_ents = []\n",
    "            for negator in negators:\n",
    "                # Note that the below gives indices of entities in transformed_sent, not the indices themselves\n",
    "                negator_pos_ents, negator_neg_ents = negator(transformed_sent, spacy_mapping, output_style=output_style)\n",
    "                for ent_idx in negator_pos_ents:\n",
    "                    if ent_idx not in pos_ents and ent_idx not in neg_ents:\n",
    "                        pos_ents.append(ent_idx)\n",
    "                for ent_idx in negator_neg_ents:\n",
    "                    if ent_idx in pos_ents:\n",
    "                        pos_ents.remove(ent_idx)\n",
    "                        neg_ents.append(ent_idx)\n",
    "                    elif ent_idx not in neg_ents:\n",
    "                        neg_ents.append(ent_idx)\n",
    "                    else:\n",
    "                        neg_ents.remove(ent_idx)\n",
    "                        pos_ents.append(ent_idx)\n",
    "\n",
    "            pos_ent_names = []\n",
    "            neg_ent_names = []\n",
    "\n",
    "            for ent_idx in pos_ents:\n",
    "                for i, phrase in enumerate(transformed_sent):\n",
    "                    if i == ent_idx:\n",
    "                        pos_ent_names.append(\" \".join(word for word in transformed_sent[i]))\n",
    "\n",
    "            for ent_idx in neg_ents:\n",
    "                for i, phrase in enumerate(transformed_sent):\n",
    "                    if i == ent_idx:\n",
    "                        neg_ent_names.append(\" \".join(word for word in transformed_sent[i]))\n",
    "\n",
    "            return pos_ent_names, neg_ent_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc2e01de-4a2a-4df7-b152-e3d7f867be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sent_list(sent_list, negators, output_style=\"tags\", word_of_interest=None):\n",
    "            \n",
    "    if output_style == \"tags\":\n",
    "        \n",
    "        preds = []\n",
    "        \n",
    "        for sent in sent_list:\n",
    "            sent_preds = predict_one_sentence(sent, negators, output_style, word_of_interest)\n",
    "            if sent_preds is not None:\n",
    "                preds.append(predict_one_sentence(sent, negators, output_style, word_of_interest))\n",
    "            \n",
    "        return preds\n",
    "            \n",
    "    if output_style == \"entities\":\n",
    "        all_pos = []\n",
    "        all_neg = []\n",
    "        \n",
    "        for sent in sent_list:\n",
    "            preds = predict_one_sentence(sent, negators, output_style, word_of_interest)\n",
    "            if preds is not None:\n",
    "                pos_ents, neg_ents = preds\n",
    "                all_pos.append(pos_ents)\n",
    "                all_neg.append(neg_ents)\n",
    "            \n",
    "        return all_pos, all_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b25c889-c676-4897-993f-c6ee0b040fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negator_output(transformed_sent, entity_indices, negated_indices, output_style):\n",
    "    \n",
    "    if output_style == \"tags\":\n",
    "        preds = []\n",
    "        k = 0\n",
    "        for i, sublist in enumerate(transformed_sent):\n",
    "            if i in negated_indices:\n",
    "                for j in range(k, k+len(sublist)):\n",
    "                    preds.append(j)\n",
    "            k += len(sublist)\n",
    "                    \n",
    "        return preds\n",
    "    \n",
    "    if output_style == \"entities\":\n",
    "        return list(set(entity_indices) - set(negated_indices)), negated_indices\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4df0fdec-c5a0-445f-9c58-8c79648e993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Looking', 'for'], ['pre', 'workout', 'Pump', 'addict'], ['instead', 'of'], ['Karbolyn', 'Hydrate']]\n",
      "([1], [3])\n"
     ]
    }
   ],
   "source": [
    "t,e = transform_sentence(neg_sents[0])\n",
    "n = [3]\n",
    "s = \"entities\"\n",
    "print(t)\n",
    "print(get_negator_output(t, e, n, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "883ada6a-5e71-449d-98d7-1b7d89118be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t,e = transform_sentence(neg_sents[0])\n",
    "n = [3]\n",
    "s = \"tags\"\n",
    "\n",
    "get_negator_output(t, e, n, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35c10bfe-6449-4c4f-960a-873912c377e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instead(transformed_sent, spacy_mapping, output_style=\"tags\"):\n",
    "    \n",
    "    string_sent = \" \".join([item for sublist in transformed_sent for item in sublist])\n",
    "    \n",
    "    doc = nlp(string_sent)\n",
    "    \n",
    "    negated_indices = []\n",
    "    \n",
    "    for ent_idx, spacy_idx in spacy_mapping.items():\n",
    "        i = spacy_idx\n",
    "        root_hits = 0\n",
    "        negated = False\n",
    "        while root_hits != 2 and negated == False:  # i.e., while there is a head. In spacy, the main clause verb is its own head\n",
    "            i = doc[i].head.i\n",
    "            if i == doc[i].head.i:\n",
    "                root_hits += 1\n",
    "            if str(doc[i]) == \"of\" and str(doc[i-1]) == \"instead\":\n",
    "                negated = True\n",
    "                \n",
    "        if negated:\n",
    "            negated_indices.append(ent_idx)\n",
    "            \n",
    "        else:\n",
    "            for i in range(6):\n",
    "                if spacy_idx - i >= 0:\n",
    "                    if doc[spacy_idx-i].text == \"instead\":\n",
    "                        negated_indices.append(ent_idx)\n",
    "                                                        \n",
    "    return get_negator_output(transformed_sent, spacy_mapping.keys(), negated_indices, output_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90ffa72c-889d-40bb-ab5e-01b85f72b70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], [3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans, ents = transform_sentence(neg_sents[0])\n",
    "spacy_mapping = get_spacy_tokens(trans, ents)\n",
    "\n",
    "instead(trans, spacy_mapping, \"entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82a43154-ab34-46a1-bc17-e36dfdbbc9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_one_sentence(neg_sents[0], [instead], \"tags\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b7b5fb7-3cdf-49bc-b455-69f17e677b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "instead_preds = predict_sent_list(neg_sents, [instead], \"entities\", word_of_interest=\"instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c3a5d7d-c2d1-4534-b094-71176c472389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['pre workout Pump addict'],\n",
       "  ['free standing', 'tubs', 'matte', 'white'],\n",
       "  ['sheer curtains', 'hooks']],\n",
       " [['Karbolyn Hydrate'], ['glossy'], ['rod']])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instead_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71c5f39d-e448-45dc-98e6-953a2cf32abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "instead_gold = prepare_gold_data(neg_sents, \"entities\", word_of_interest=\"instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84f0a772-7463-496f-848f-d635b078aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['pre workout Pump addict'],\n",
       "  ['free standing', 'tubs', 'matte', 'white'],\n",
       "  ['sheer curtains', 'hooks']],\n",
       " [['Karbolyn Hydrate'], ['glossy'], ['rod']])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instead_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3381c412-f39d-48fd-80cb-524346c3c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation config: entities\n",
      "Accuracy: 100%\n",
      "Precision: 100%\n",
      "Recall: 100%\n",
      "F1: 100%\n"
     ]
    }
   ],
   "source": [
    "evaluate(instead_preds, instead_gold, \"entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "866542fc-fa27-44bb-a1f3-3605212049df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(sent_list, negators, output_type=\"tags\", word_of_interest=None):\n",
    "\n",
    "    preds = predict_sent_list(sent_list, negators, output_type, word_of_interest)\n",
    "    gold = prepare_gold_data(sent_list, output_type, word_of_interest)\n",
    "    \n",
    "    evaluate(preds, gold, output_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c421479-4464-4a9a-8493-d45a70b166a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation config: entities\n",
      "Accuracy: 100%\n",
      "Precision: 100%\n",
      "Recall: 100%\n",
      "F1: 100%\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(neg_sents, [instead], \"entities\", \"instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "965a9e32-d009-4e2e-8aab-2a4433b7bfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation config: tags\n",
      "Accuracy: 100%\n",
      "Precision: 100%\n",
      "Recall: 100%\n",
      "F1: 100%\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(neg_sents, [instead], \"tags\", \"instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262cc68-9633-4f9e-800f-af78a22a7de7",
   "metadata": {},
   "source": [
    "### Reasons why scope detection is not always successful (based on partial sample of sentences):\n",
    "- No negator:\n",
    "  - instead (3)\n",
    "  - without (4)\n",
    "  - comparative (1) (e.g. \"deeper than a regular-True tub\")\n",
    "  - negation scope would include entities we don't want to be negated (2) (e.g., \"counter top with no drill-True holes-True for the faucet-False\")\n",
    "  - can X be removed (1)\n",
    "  - negative affix (1)\n",
    "- Miscellaneous:\n",
    "  - \"I would like to know if the wool-like top side is soft as well, or if it is scratchy-True\"\n",
    "  - \"You have it for the gold-True and black-True but i don't [sic] want it for the navy\"\n",
    "  - \"I found a vanity top I love but it has only one-True hole-True for taps and that doesn't suit our needs\"\n",
    " \n",
    " \n",
    "Not sure:\n",
    "- I'm looking for X, not Y or Z-True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a533835-b639-46d1-8fcc-15573e4d950a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ways of indicating negation (incomplete):\n",
    "\n",
    "- \"don't want (any)\"\n",
    "- \"no\"\n",
    "- \"no more than\"\n",
    "- \"less than\"\n",
    "- \"un-\"\n",
    "- \"without\"\n",
    "- \"only\"\n",
    "- \"-less\"\n",
    "- \"instead of\"\n",
    "- \"too\" (what comes before is negated, e.g. in \"pink is too light\", \"pink\" is negated)\n",
    "- \"not too\" (what comes after is negated, e.g. in \"not too light\", \"light\" is negated)\n",
    "- \"the website only gives the option of\"\n",
    "- \"without X or Y\" (two separately annotated entities separated by conjunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d882b-ef9a-4be8-a76b-969dc8da27c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
