{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-16T21:11:44.933683Z","iopub.execute_input":"2022-05-16T21:11:44.934289Z","iopub.status.idle":"2022-05-16T21:11:44.964939Z","shell.execute_reply.started":"2022-05-16T21:11:44.934196Z","shell.execute_reply":"2022-05-16T21:11:44.964171Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification,AutoConfig","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:03.000962Z","iopub.execute_input":"2022-05-16T21:18:03.001711Z","iopub.status.idle":"2022-05-16T21:18:03.006891Z","shell.execute_reply.started":"2022-05-16T21:18:03.001666Z","shell.execute_reply":"2022-05-16T21:18:03.006039Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"un_neg_data= pd.read_csv(\"../input/nertag/unnegated_File_Name.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:05.666850Z","iopub.execute_input":"2022-05-16T21:18:05.667189Z","iopub.status.idle":"2022-05-16T21:18:05.689893Z","shell.execute_reply.started":"2022-05-16T21:18:05.667150Z","shell.execute_reply":"2022-05-16T21:18:05.688925Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\ndata = pd.read_csv(\"../input/nertag/File_Name.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:31:07.362299Z","iopub.execute_input":"2022-05-16T15:31:07.362858Z","iopub.status.idle":"2022-05-16T15:31:07.379991Z","shell.execute_reply.started":"2022-05-16T15:31:07.362820Z","shell.execute_reply":"2022-05-16T15:31:07.379301Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"un_neg_data","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:07.793898Z","iopub.execute_input":"2022-05-16T21:18:07.794598Z","iopub.status.idle":"2022-05-16T21:18:07.814489Z","shell.execute_reply.started":"2022-05-16T21:18:07.794565Z","shell.execute_reply":"2022-05-16T21:18:07.812954Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"secondary_data = pd.read_csv(\"../input/nertag/clean_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:31:11.834013Z","iopub.execute_input":"2022-05-16T15:31:11.834767Z","iopub.status.idle":"2022-05-16T15:31:11.848520Z","shell.execute_reply.started":"2022-05-16T15:31:11.834730Z","shell.execute_reply":"2022-05-16T15:31:11.847652Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data= pd.read_csv(\"../input/nertag/un-negated_clean_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:11.233068Z","iopub.execute_input":"2022-05-16T21:18:11.233645Z","iopub.status.idle":"2022-05-16T21:18:11.246915Z","shell.execute_reply.started":"2022-05-16T21:18:11.233608Z","shell.execute_reply":"2022-05-16T21:18:11.246204Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"unneg_secondary_data","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:14.744692Z","iopub.execute_input":"2022-05-16T21:18:14.745541Z","iopub.status.idle":"2022-05-16T21:18:14.760595Z","shell.execute_reply.started":"2022-05-16T21:18:14.745491Z","shell.execute_reply":"2022-05-16T21:18:14.759754Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"labels_to_ids = {k: v for v, k in enumerate(unneg_secondary_data.Tags.unique())}\nids_to_labels = {v: k for v, k in enumerate(unneg_secondary_data.Tags.unique())}\nlabels_to_ids","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:17.734622Z","iopub.execute_input":"2022-05-16T21:18:17.734880Z","iopub.status.idle":"2022-05-16T21:18:17.751274Z","shell.execute_reply.started":"2022-05-16T21:18:17.734852Z","shell.execute_reply":"2022-05-16T21:18:17.750448Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128\nTRAIN_BATCH_SIZE = 4\nVALID_BATCH_SIZE = 2\nEPOCHS = 3\nLEARNING_RATE = 1e-03\nMAX_GRAD_NORM = 10\n# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:23:51.871712Z","iopub.execute_input":"2022-05-16T21:23:51.871999Z","iopub.status.idle":"2022-05-16T21:23:51.877151Z","shell.execute_reply.started":"2022-05-16T21:23:51.871960Z","shell.execute_reply":"2022-05-16T21:23:51.876051Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class dataset(Dataset):\n  def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n  def __getitem__(self, index):\n        # step 1: get the sentence and word labels \n        sentence = self.data.Sentence[index].strip().split()  \n        word_labels = self.data.Tags[index].split(\",\") \n\n        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n        encoding = self.tokenizer(sentence,\n                             is_pretokenized=True, \n                             return_offsets_mapping=True, \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len)\n        \n        # step 3: create token labels only for first word pieces of each tokenized word\n        labels = [labels_to_ids[label] for label in word_labels] \n        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n        # create an empty array of -100 of length max_length\n        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n        \n        # set only labels whose first offset position is 0 and the second is not 0\n        i = 0\n        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n          if mapping[0] == 0 and mapping[1] != 0:\n            # overwrite label\n            encoded_labels[idx] = labels[i]\n            i += 1\n\n        # step 4: turn everything into PyTorch tensors\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n        item['labels'] = torch.as_tensor(encoded_labels)\n        \n        return item\n\n  def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:25.951893Z","iopub.execute_input":"2022-05-16T21:18:25.952179Z","iopub.status.idle":"2022-05-16T21:18:25.962782Z","shell.execute_reply.started":"2022-05-16T21:18:25.952147Z","shell.execute_reply":"2022-05-16T21:18:25.961654Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\",use_fast=True)\n# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:31:26.293785Z","iopub.execute_input":"2022-05-16T15:31:26.294571Z","iopub.status.idle":"2022-05-16T15:31:30.658826Z","shell.execute_reply.started":"2022-05-16T15:31:26.294521Z","shell.execute_reply":"2022-05-16T15:31:30.658113Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_dataset = un_neg_data.sample(frac=train_size,random_state=200)\ntest_dataset = un_neg_data.drop(train_dataset.index).reset_index(drop=True)\ntrain_dataset = train_dataset.reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(un_neg_data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = dataset(train_dataset, tokenizer, MAX_LEN)\ntesting_set = dataset(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:32.795720Z","iopub.execute_input":"2022-05-16T21:18:32.795985Z","iopub.status.idle":"2022-05-16T21:18:32.808339Z","shell.execute_reply.started":"2022-05-16T21:18:32.795956Z","shell.execute_reply":"2022-05-16T21:18:32.807156Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"training_set[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:35.283175Z","iopub.execute_input":"2022-05-16T21:18:35.283662Z","iopub.status.idle":"2022-05-16T21:18:35.298645Z","shell.execute_reply.started":"2022-05-16T21:18:35.283625Z","shell.execute_reply":"2022-05-16T21:18:35.297723Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n  print('{0:10}  {1}'.format(token, label))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:23:47.570567Z","iopub.execute_input":"2022-05-16T15:23:47.571203Z","iopub.status.idle":"2022-05-16T15:23:47.599036Z","shell.execute_reply.started":"2022-05-16T15:23:47.571165Z","shell.execute_reply":"2022-05-16T15:23:47.598381Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:47.956049Z","iopub.execute_input":"2022-05-16T21:18:47.956615Z","iopub.status.idle":"2022-05-16T21:18:47.961193Z","shell.execute_reply.started":"2022-05-16T21:18:47.956580Z","shell.execute_reply":"2022-05-16T21:18:47.960494Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:18:51.174921Z","iopub.execute_input":"2022-05-16T21:18:51.175444Z","iopub.status.idle":"2022-05-16T21:18:51.232791Z","shell.execute_reply.started":"2022-05-16T21:18:51.175404Z","shell.execute_reply":"2022-05-16T21:18:51.231883Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:19:10.191418Z","iopub.execute_input":"2022-05-16T21:19:10.191671Z","iopub.status.idle":"2022-05-16T21:19:39.986594Z","shell.execute_reply.started":"2022-05-16T21:19:10.191644Z","shell.execute_reply":"2022-05-16T21:19:39.985921Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, BertConfig\n\nconfig = AutoConfig.from_pretrained(\"dslim/bert-base-NER\")\nconfig.num_labels = 28\nmodel = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\", config =config)\nmodel.parameters","metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:43:33.058849Z","iopub.execute_input":"2022-05-16T15:43:33.059178Z","iopub.status.idle":"2022-05-16T15:43:36.625781Z","shell.execute_reply.started":"2022-05-16T15:43:33.059146Z","shell.execute_reply":"2022-05-16T15:43:36.624777Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"inputs = training_set[2]\ninput_ids = inputs[\"input_ids\"].unsqueeze(0)\nattention_mask = inputs[\"attention_mask\"].unsqueeze(0)\nlabels = inputs[\"labels\"].unsqueeze(0)\n\ninput_ids = input_ids.to(device)\nattention_mask = attention_mask.to(device)\nlabels = labels.to(device)\n\noutputs = model(input_ids, attention_mask=attention_mask, labels=labels)\ninitial_loss = outputs[0]\ninitial_loss","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:19:46.891608Z","iopub.execute_input":"2022-05-16T21:19:46.891895Z","iopub.status.idle":"2022-05-16T21:19:47.903611Z","shell.execute_reply.started":"2022-05-16T21:19:46.891865Z","shell.execute_reply":"2022-05-16T21:19:47.902833Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tr_logits = outputs[1]\ntr_logits.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:19:50.668387Z","iopub.execute_input":"2022-05-16T21:19:50.669125Z","iopub.status.idle":"2022-05-16T21:19:50.675548Z","shell.execute_reply.started":"2022-05-16T21:19:50.669066Z","shell.execute_reply":"2022-05-16T21:19:50.674135Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:24:09.616900Z","iopub.execute_input":"2022-05-16T21:24:09.617461Z","iopub.status.idle":"2022-05-16T21:24:09.625439Z","shell.execute_reply.started":"2022-05-16T21:24:09.617422Z","shell.execute_reply":"2022-05-16T21:24:09.624256Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Defining the training function on the 80% of the dataset for tuning the bert model\ndef train(epoch):\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    tr_preds, tr_labels = [], []\n    # put model in training mode\n    model.train()\n    \n    for idx, batch in enumerate(training_loader):\n        \n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        labels = batch['labels'].to(device, dtype = torch.long)\n\n        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n        \n        if idx % 100==0:\n            loss_step = tr_loss/nb_tr_steps\n            print(f\"Training loss per 100 training steps: {loss_step}\")\n           \n        # compute training accuracy\n        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n        \n        # only compute accuracy at active labels\n        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n        \n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        \n        tr_labels.extend(labels)\n        tr_preds.extend(predictions)\n\n        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n        tr_accuracy += tmp_tr_accuracy\n    \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:24:12.020621Z","iopub.execute_input":"2022-05-16T21:24:12.021046Z","iopub.status.idle":"2022-05-16T21:24:12.032846Z","shell.execute_reply.started":"2022-05-16T21:24:12.021013Z","shell.execute_reply":"2022-05-16T21:24:12.031793Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    print(f\"Training epoch: {epoch + 1}\")\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:24:14.784178Z","iopub.execute_input":"2022-05-16T21:24:14.784718Z","iopub.status.idle":"2022-05-16T21:24:19.287044Z","shell.execute_reply.started":"2022-05-16T21:24:14.784679Z","shell.execute_reply":"2022-05-16T21:24:19.285434Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    # put model in evaluation mode\n    model.eval()\n    \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_examples, nb_eval_steps = 0, 0\n    eval_preds, eval_labels = [], []\n    \n    with torch.no_grad():\n        for idx, batch in enumerate(testing_loader):\n            \n            ids = batch['input_ids'].to(device, dtype = torch.long)\n            mask = batch['attention_mask'].to(device, dtype = torch.long)\n            labels = batch['labels'].to(device, dtype = torch.long)\n            \n            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n            \n            eval_loss += loss.item()\n\n            nb_eval_steps += 1\n            nb_eval_examples += labels.size(0)\n        \n            if idx % 100==0:\n                loss_step = eval_loss/nb_eval_steps\n                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n              \n            # compute evaluation accuracy\n            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n            \n            # only compute accuracy at active labels\n            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        \n            labels = torch.masked_select(flattened_targets, active_accuracy)\n            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n            \n            eval_labels.extend(labels)\n            eval_preds.extend(predictions)\n            \n            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n            eval_accuracy += tmp_eval_accuracy\n\n    labels = [ids_to_labels[id.item()] for id in eval_labels]\n    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n    \n    eval_loss = eval_loss / nb_eval_steps\n    eval_accuracy = eval_accuracy / nb_eval_steps\n    print(f\"Validation Loss: {eval_loss}\")\n    print(f\"Validation Accuracy: {eval_accuracy}\")\n\n    return labels, predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:24:23.315615Z","iopub.execute_input":"2022-05-16T21:24:23.315874Z","iopub.status.idle":"2022-05-16T21:24:23.330100Z","shell.execute_reply.started":"2022-05-16T21:24:23.315846Z","shell.execute_reply":"2022-05-16T21:24:23.329313Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"labels, predictions = valid(model, testing_loader)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:24:27.662988Z","iopub.execute_input":"2022-05-16T21:24:27.663382Z","iopub.status.idle":"2022-05-16T21:24:27.839828Z","shell.execute_reply.started":"2022-05-16T21:24:27.663350Z","shell.execute_reply":"2022-05-16T21:24:27.838971Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:24:30.869683Z","iopub.execute_input":"2022-05-16T21:24:30.869991Z","iopub.status.idle":"2022-05-16T21:24:30.894865Z","shell.execute_reply.started":"2022-05-16T21:24:30.869956Z","shell.execute_reply":"2022-05-16T21:24:30.894259Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:43:17.219622Z","iopub.execute_input":"2022-05-16T14:43:17.220429Z","iopub.status.idle":"2022-05-16T14:43:31.664489Z","shell.execute_reply.started":"2022-05-16T14:43:17.220383Z","shell.execute_reply":"2022-05-16T14:43:31.663611Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from seqeval.metrics import classification_report\n\nprint(classification_report(labels, predictions))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:43:36.510850Z","iopub.execute_input":"2022-05-16T14:43:36.511215Z","iopub.status.idle":"2022-05-16T14:43:36.565174Z","shell.execute_reply.started":"2022-05-16T14:43:36.511174Z","shell.execute_reply":"2022-05-16T14:43:36.564176Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-16T14:51:27.034528Z","iopub.execute_input":"2022-05-16T14:51:27.034795Z","iopub.status.idle":"2022-05-16T14:51:27.046787Z","shell.execute_reply.started":"2022-05-16T14:51:27.034761Z","shell.execute_reply":"2022-05-16T14:51:27.046075Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install tokenizers --upgrade","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers --upgrade","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizerFast\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\ntexts = ['I am looking for a black gloss 33 inch fireclay apron sink', 'Short and stout']\ntokenizer.batch_encode_plus(texts, is_pretokenized = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T00:13:15.027447Z","iopub.execute_input":"2022-05-16T00:13:15.027812Z","iopub.status.idle":"2022-05-16T00:13:15.883499Z","shell.execute_reply.started":"2022-05-16T00:13:15.027774Z","shell.execute_reply":"2022-05-16T00:13:15.882014Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import tokenizers\ntokenizers.__version__","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:17:39.876919Z","iopub.execute_input":"2022-05-16T21:17:39.877881Z","iopub.status.idle":"2022-05-16T21:17:39.898272Z","shell.execute_reply.started":"2022-05-16T21:17:39.877839Z","shell.execute_reply":"2022-05-16T21:17:39.897461Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import transformers\ntransformers.__version__","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:17:42.341533Z","iopub.execute_input":"2022-05-16T21:17:42.342211Z","iopub.status.idle":"2022-05-16T21:17:51.150188Z","shell.execute_reply.started":"2022-05-16T21:17:42.342172Z","shell.execute_reply":"2022-05-16T21:17:51.149169Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"pip install tokenizers==0.8.0rc4","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:17:09.215572Z","iopub.execute_input":"2022-05-16T21:17:09.216114Z","iopub.status.idle":"2022-05-16T21:17:20.664873Z","shell.execute_reply.started":"2022-05-16T21:17:09.215997Z","shell.execute_reply":"2022-05-16T21:17:20.663976Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install transformers==3.0.1","metadata":{"execution":{"iopub.status.busy":"2022-05-16T21:17:20.667025Z","iopub.execute_input":"2022-05-16T21:17:20.667320Z","iopub.status.idle":"2022-05-16T21:17:32.859114Z","shell.execute_reply.started":"2022-05-16T21:17:20.667283Z","shell.execute_reply":"2022-05-16T21:17:32.858296Z"},"trusted":true},"execution_count":2,"outputs":[]}]}