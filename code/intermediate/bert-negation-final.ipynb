{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-07T02:55:24.650256Z",
     "iopub.status.busy": "2022-06-07T02:55:24.649868Z",
     "iopub.status.idle": "2022-06-07T02:55:24.688505Z",
     "shell.execute_reply": "2022-06-07T02:55:24.687689Z",
     "shell.execute_reply.started": "2022-06-07T02:55:24.650180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nertag/SOCC_negation.tsv\n",
      "/kaggle/input/nertag/clean_data.csv\n",
      "/kaggle/input/nertag/unnegated_File_Name.csv\n",
      "/kaggle/input/nertag/un-negated_clean_data.csv\n",
      "/kaggle/input/nertag/File_Name.csv\n",
      "/kaggle/input/nertag/reannotated_val.csv\n",
      "/kaggle/input/nertag/Heyday_validationdata.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the transformers and tokenizer versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/mrinalgrover/opt/miniconda3/lib/python3.9/site-packages (22.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers==0.8.1\n",
      "  Using cached tokenizers-0.8.1.tar.gz (97 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[46 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/byte_level_bpe.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/base_tokenizer.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/char_level_bpe.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/bert_wordpiece.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.pyi -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.pyi -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.pyi -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.pyi -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.pyi -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.pyi -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:55:52.074077Z",
     "iopub.status.busy": "2022-06-07T02:55:52.073162Z",
     "iopub.status.idle": "2022-06-07T02:56:07.781482Z",
     "shell.execute_reply": "2022-06-07T02:56:07.780601Z",
     "shell.execute_reply.started": "2022-06-07T02:55:52.074039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.1\n",
      "  Downloading transformers-3.0.1-py3-none-any.whl (757 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.2/757.2 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (21.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (0.1.96)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (4.63.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (2.27.1)\n",
      "Requirement already satisfied: tokenizers==0.8.0-rc4 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (0.8.0rc4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (3.6.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.1) (0.0.53)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.1) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.1) (2021.10.8)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.1) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.1) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.1) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers==3.0.1) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.1) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.1) (4.2.0)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.18.0\n",
      "    Uninstalling transformers-4.18.0:\n",
      "      Successfully uninstalled transformers-4.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "allennlp 2.9.3 requires transformers<4.19,>=4.1, but you have transformers 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed transformers-3.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==3.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T06:23:41.033954Z",
     "iopub.status.busy": "2022-06-06T06:23:41.033693Z",
     "iopub.status.idle": "2022-06-06T06:23:49.565417Z",
     "shell.execute_reply": "2022-06-06T06:23:49.564635Z",
     "shell.execute_reply.started": "2022-06-06T06:23:41.033919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.0.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:07.786955Z",
     "iopub.status.busy": "2022-06-07T02:56:07.786662Z",
     "iopub.status.idle": "2022-06-07T02:56:07.821886Z",
     "shell.execute_reply": "2022-06-07T02:56:07.821100Z",
     "shell.execute_reply.started": "2022-06-07T02:56:07.786914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0.rc4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tokenizers\n",
    "tokenizers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:07.828359Z",
     "iopub.status.busy": "2022-06-07T02:56:07.826232Z",
     "iopub.status.idle": "2022-06-07T02:56:17.628283Z",
     "shell.execute_reply": "2022-06-07T02:56:17.627178Z",
     "shell.execute_reply.started": "2022-06-07T02:56:07.828309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the SOCC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:17.631178Z",
     "iopub.status.busy": "2022-06-07T02:56:17.630662Z",
     "iopub.status.idle": "2022-06-07T02:56:17.711769Z",
     "shell.execute_reply": "2022-06-07T02:56:17.710929Z",
     "shell.execute_reply.started": "2022-06-07T02:56:17.631131Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_data_socc= pd.read_csv(\"../input/nertag/SOCC_negation.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:21.478564Z",
     "iopub.status.busy": "2022-06-07T02:56:21.477925Z",
     "iopub.status.idle": "2022-06-07T02:56:21.503126Z",
     "shell.execute_reply": "2022-06-07T02:56:21.502299Z",
     "shell.execute_reply.started": "2022-06-07T02:56:21.478524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_index</th>\n",
       "      <th>Token_index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Europe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>has</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>done</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>HUGE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54883</th>\n",
       "      <td>2595</td>\n",
       "      <td>48</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54884</th>\n",
       "      <td>2595</td>\n",
       "      <td>49</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54885</th>\n",
       "      <td>2595</td>\n",
       "      <td>50</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>2595</td>\n",
       "      <td>51</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54887</th>\n",
       "      <td>2595</td>\n",
       "      <td>52</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54888 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence_index  Token_index   Token  Negation\n",
       "0                   0            1  Europe     False\n",
       "1                   0            2     has     False\n",
       "2                   0            3    done     False\n",
       "3                   0            4       a     False\n",
       "4                   0            5    HUGE     False\n",
       "...               ...          ...     ...       ...\n",
       "54883            2595           48       ,     False\n",
       "54884            2595           49    none     False\n",
       "54885            2595           50       ,     False\n",
       "54886            2595           51       ,     False\n",
       "54887            2595           52       ,     False\n",
       "\n",
       "[54888 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation_data_socc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:25.320033Z",
     "iopub.status.busy": "2022-06-07T02:56:25.319733Z",
     "iopub.status.idle": "2022-06-07T02:56:25.354534Z",
     "shell.execute_reply": "2022-06-07T02:56:25.353636Z",
     "shell.execute_reply.started": "2022-06-07T02:56:25.319995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54888 entries, 0 to 54887\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Sentence_index  54888 non-null  int64 \n",
      " 1   Token_index     54888 non-null  int64 \n",
      " 2   Token           54888 non-null  object\n",
      " 3   Negation        54888 non-null  bool  \n",
      "dtypes: bool(1), int64(2), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "negation_data_socc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:27.935207Z",
     "iopub.status.busy": "2022-06-07T02:56:27.934898Z",
     "iopub.status.idle": "2022-06-07T02:56:27.951301Z",
     "shell.execute_reply": "2022-06-07T02:56:27.950334Z",
     "shell.execute_reply.started": "2022-06-07T02:56:27.935170Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_data_socc['Negation'] = negation_data_socc['Negation'].map({True: 'True', False: 'False'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:30.852662Z",
     "iopub.status.busy": "2022-06-07T02:56:30.851908Z",
     "iopub.status.idle": "2022-06-07T02:56:31.102474Z",
     "shell.execute_reply": "2022-06-07T02:56:31.101600Z",
     "shell.execute_reply.started": "2022-06-07T02:56:30.852620Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_data_socc['Sentence']= negation_data_socc[['Sentence_index','Token','Negation']].groupby(['Sentence_index'])['Token'].transform(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:32.646654Z",
     "iopub.status.busy": "2022-06-07T02:56:32.646379Z",
     "iopub.status.idle": "2022-06-07T02:56:32.886669Z",
     "shell.execute_reply": "2022-06-07T02:56:32.885855Z",
     "shell.execute_reply.started": "2022-06-07T02:56:32.646625Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_data_socc['Negation']= negation_data_socc[['Sentence_index','Token','Negation']].groupby(['Sentence_index'])['Negation'].transform(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:35.323074Z",
     "iopub.status.busy": "2022-06-07T02:56:35.322814Z",
     "iopub.status.idle": "2022-06-07T02:56:35.329385Z",
     "shell.execute_reply": "2022-06-07T02:56:35.328564Z",
     "shell.execute_reply.started": "2022-06-07T02:56:35.323044Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_data_socc = negation_data_socc[['Sentence','Negation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:38.772873Z",
     "iopub.status.busy": "2022-06-07T02:56:38.772108Z",
     "iopub.status.idle": "2022-06-07T02:56:38.818731Z",
     "shell.execute_reply": "2022-06-07T02:56:38.817909Z",
     "shell.execute_reply.started": "2022-06-07T02:56:38.772824Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_data_socc = negation_data_socc.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:43.208952Z",
     "iopub.status.busy": "2022-06-07T02:56:43.208480Z",
     "iopub.status.idle": "2022-06-07T02:56:43.224623Z",
     "shell.execute_reply": "2022-06-07T02:56:43.223596Z",
     "shell.execute_reply.started": "2022-06-07T02:56:43.208917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe has done a HUGE amount to help refugees...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But that is not going to happen !</td>\n",
       "      <td>False,False,False,False,True,True,True,False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilary did not lose because she was a woman .</td>\n",
       "      <td>False,False,False,True,True,True,True,True,Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She lost because the US had their version of a...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A restless electorate wanted an outsider .</td>\n",
       "      <td>False,False,False,False,False,False,False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>We are going to tell them that plenty of other...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>Some of them even ' third world countries ' . ...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>We are going to tell them , when they run for ...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>Or the job.And we are going to tell our sons t...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>OMG , , , someone who has understanding , , , ...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2578 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  \\\n",
       "0     Europe has done a HUGE amount to help refugees...   \n",
       "1                     But that is not going to happen !   \n",
       "2         Hilary did not lose because she was a woman .   \n",
       "3     She lost because the US had their version of a...   \n",
       "4            A restless electorate wanted an outsider .   \n",
       "...                                                 ...   \n",
       "2573  We are going to tell them that plenty of other...   \n",
       "2574  Some of them even ' third world countries ' . ...   \n",
       "2575  We are going to tell them , when they run for ...   \n",
       "2576  Or the job.And we are going to tell our sons t...   \n",
       "2577  OMG , , , someone who has understanding , , , ...   \n",
       "\n",
       "                                               Negation  \n",
       "0     False,False,False,False,False,False,False,Fals...  \n",
       "1          False,False,False,False,True,True,True,False  \n",
       "2     False,False,False,True,True,True,True,True,Tru...  \n",
       "3     False,False,False,False,False,False,False,Fals...  \n",
       "4             False,False,False,False,False,False,False  \n",
       "...                                                 ...  \n",
       "2573  False,False,False,False,False,False,False,Fals...  \n",
       "2574  False,False,False,False,False,False,False,Fals...  \n",
       "2575  False,False,False,False,False,False,False,Fals...  \n",
       "2576  False,False,False,False,False,False,False,Fals...  \n",
       "2577  False,False,False,False,False,False,False,Fals...  \n",
       "\n",
       "[2578 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation_data_socc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:47.164587Z",
     "iopub.status.busy": "2022-06-07T02:56:47.164148Z",
     "iopub.status.idle": "2022-06-07T02:56:47.171314Z",
     "shell.execute_reply": "2022-06-07T02:56:47.170442Z",
     "shell.execute_reply.started": "2022-06-07T02:56:47.164546Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_to_ids = {'True':1,'False':0}\n",
    "ids_to_labels = {1: 'True', 0: 'False'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:56:58.854980Z",
     "iopub.status.busy": "2022-06-07T02:56:58.854691Z",
     "iopub.status.idle": "2022-06-07T02:56:59.786596Z",
     "shell.execute_reply": "2022-06-07T02:56:59.785854Z",
     "shell.execute_reply.started": "2022-06-07T02:56:58.854946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baac424462db40a99ad67854ecc9438a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:03.659916Z",
     "iopub.status.busy": "2022-06-07T02:57:03.659623Z",
     "iopub.status.idle": "2022-06-07T02:57:03.671138Z",
     "shell.execute_reply": "2022-06-07T02:57:03.670079Z",
     "shell.execute_reply.started": "2022-06-07T02:57:03.659883Z"
    }
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.Sentence[index].strip().split()  \n",
    "        word_labels = self.data.Negation[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             is_pretokenized=True, \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:08.248194Z",
     "iopub.status.busy": "2022-06-07T02:57:08.247877Z",
     "iopub.status.idle": "2022-06-07T02:57:08.265929Z",
     "shell.execute_reply": "2022-06-07T02:57:08.264911Z",
     "shell.execute_reply.started": "2022-06-07T02:57:08.248157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2578, 2)\n",
      "TRAIN Dataset: (2058, 2)\n",
      "TEST Dataset: (513, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = negation_data_socc.sample(frac=train_size,random_state=200)\n",
    "test_dataset = negation_data_socc.drop(train_dataset.index).reset_index(drop=True)\n",
    "test_dataset.drop(test_dataset.index[[233, 234, 457]], inplace=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "train_dataset.drop(train_dataset.index[[573, 1506, 1603, 1700]], inplace=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(negation_data_socc.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and wrangling the HeyDay validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:12.356759Z",
     "iopub.status.busy": "2022-06-07T02:57:12.356008Z",
     "iopub.status.idle": "2022-06-07T02:57:12.370004Z",
     "shell.execute_reply": "2022-06-07T02:57:12.368945Z",
     "shell.execute_reply.started": "2022-06-07T02:57:12.356719Z"
    }
   },
   "outputs": [],
   "source": [
    "external_valset= pd.read_csv(\"../input/nertag/un-negated_clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:15.821046Z",
     "iopub.status.busy": "2022-06-07T02:57:15.820465Z",
     "iopub.status.idle": "2022-06-07T02:57:15.836037Z",
     "shell.execute_reply": "2022-06-07T02:57:15.835262Z",
     "shell.execute_reply.started": "2022-06-07T02:57:15.821005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>is_negative</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>30</td>\n",
       "      <td>B-SIZE</td>\n",
       "      <td>False</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>inch</td>\n",
       "      <td>I-SIZE</td>\n",
       "      <td>False</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>white</td>\n",
       "      <td>B-COLOUR</td>\n",
       "      <td>False</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>desk</td>\n",
       "      <td>B-PRODUCT</td>\n",
       "      <td>False</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>set</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "      <td>False</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2350 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokens       Tags  is_negative  sentence\n",
       "0           I          O        False         0\n",
       "1          am          O        False         0\n",
       "2     looking          O        False         0\n",
       "3         for          O        False         0\n",
       "4           a          O        False         0\n",
       "...       ...        ...          ...       ...\n",
       "2345       30     B-SIZE        False       166\n",
       "2346     inch     I-SIZE        False       166\n",
       "2347    white   B-COLOUR        False       166\n",
       "2348     desk  B-PRODUCT        False       166\n",
       "2349      set  I-PRODUCT        False       166\n",
       "\n",
       "[2350 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:19.072072Z",
     "iopub.status.busy": "2022-06-07T02:57:19.071678Z",
     "iopub.status.idle": "2022-06-07T02:57:19.150661Z",
     "shell.execute_reply": "2022-06-07T02:57:19.148584Z",
     "shell.execute_reply.started": "2022-06-07T02:57:19.072014Z"
    }
   },
   "outputs": [],
   "source": [
    "external_valset[\"Sentence\"]= external_valset[[\"Tokens\",\"is_negative\",\"sentence\"]].groupby([\"sentence\"])[\"Tokens\"].transform(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:21.455380Z",
     "iopub.status.busy": "2022-06-07T02:57:21.454591Z",
     "iopub.status.idle": "2022-06-07T02:57:21.461203Z",
     "shell.execute_reply": "2022-06-07T02:57:21.460356Z",
     "shell.execute_reply.started": "2022-06-07T02:57:21.455317Z"
    }
   },
   "outputs": [],
   "source": [
    "external_valset['is_negative'] = external_valset['is_negative'].map({True: 'True', False: 'False'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:23.706474Z",
     "iopub.status.busy": "2022-06-07T02:57:23.706189Z",
     "iopub.status.idle": "2022-06-07T02:57:23.735785Z",
     "shell.execute_reply": "2022-06-07T02:57:23.735020Z",
     "shell.execute_reply.started": "2022-06-07T02:57:23.706442Z"
    }
   },
   "outputs": [],
   "source": [
    "external_valset[\"Negation\"]= external_valset[[\"Tokens\",\"is_negative\",\"sentence\"]].groupby([\"sentence\"])[\"is_negative\"].transform(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:26.246157Z",
     "iopub.status.busy": "2022-06-07T02:57:26.245383Z",
     "iopub.status.idle": "2022-06-07T02:57:26.254054Z",
     "shell.execute_reply": "2022-06-07T02:57:26.253139Z",
     "shell.execute_reply.started": "2022-06-07T02:57:26.246110Z"
    }
   },
   "outputs": [],
   "source": [
    "external_valset = external_valset[['Sentence','Negation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:28.890175Z",
     "iopub.status.busy": "2022-06-07T02:57:28.889862Z",
     "iopub.status.idle": "2022-06-07T02:57:28.897812Z",
     "shell.execute_reply": "2022-06-07T02:57:28.897025Z",
     "shell.execute_reply.started": "2022-06-07T02:57:28.890139Z"
    }
   },
   "outputs": [],
   "source": [
    "external_valset = external_valset.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:31.893439Z",
     "iopub.status.busy": "2022-06-07T02:57:31.892640Z",
     "iopub.status.idle": "2022-06-07T02:57:31.905870Z",
     "shell.execute_reply": "2022-06-07T02:57:31.905120Z",
     "shell.execute_reply.started": "2022-06-07T02:57:31.893375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am looking for a black gloss 33 inch firecla...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Looking for pre workout Pump addict instead of...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i need a 48 inch glass sliding goof and a show...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, do any of your free standing tubs have ...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm looking for a 24 inch white mirror that is...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>What rectangular shower units are available?</td>\n",
       "      <td>False,False,False,False,False,False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>I am looking for a 35 inch bathroom sink count...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>I'm looking f or a Black Matte bathtub double ...</td>\n",
       "      <td>False,False,False,False,False,False,False,Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Need a 27 inch frameless shower door</td>\n",
       "      <td>False,False,False,False,False,False,False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Looking for 30 inch white desk set</td>\n",
       "      <td>False,False,False,False,False,False,False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  \\\n",
       "0    I am looking for a black gloss 33 inch firecla...   \n",
       "1    Looking for pre workout Pump addict instead of...   \n",
       "2    i need a 48 inch glass sliding goof and a show...   \n",
       "3    Hello, do any of your free standing tubs have ...   \n",
       "4    I'm looking for a 24 inch white mirror that is...   \n",
       "..                                                 ...   \n",
       "162       What rectangular shower units are available?   \n",
       "163  I am looking for a 35 inch bathroom sink count...   \n",
       "164  I'm looking f or a Black Matte bathtub double ...   \n",
       "165               Need a 27 inch frameless shower door   \n",
       "166                 Looking for 30 inch white desk set   \n",
       "\n",
       "                                              Negation  \n",
       "0    False,False,False,False,False,False,False,Fals...  \n",
       "1    False,False,False,False,False,False,False,Fals...  \n",
       "2    False,False,False,False,False,False,False,Fals...  \n",
       "3    False,False,False,False,False,False,False,Fals...  \n",
       "4    False,False,False,False,False,False,False,Fals...  \n",
       "..                                                 ...  \n",
       "162                False,False,False,False,False,False  \n",
       "163  False,False,False,False,False,False,False,Fals...  \n",
       "164  False,False,False,False,False,False,False,Fals...  \n",
       "165          False,False,False,False,False,False,False  \n",
       "166          False,False,False,False,False,False,False  \n",
       "\n",
       "[167 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:35.868268Z",
     "iopub.status.busy": "2022-06-07T02:57:35.867801Z",
     "iopub.status.idle": "2022-06-07T02:57:35.873068Z",
     "shell.execute_reply": "2022-06-07T02:57:35.872320Z",
     "shell.execute_reply.started": "2022-06-07T02:57:35.868221Z"
    }
   },
   "outputs": [],
   "source": [
    "final_validation_set = dataset(external_valset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:39.294806Z",
     "iopub.status.busy": "2022-06-07T02:57:39.294414Z",
     "iopub.status.idle": "2022-06-07T02:57:39.305335Z",
     "shell.execute_reply": "2022-06-07T02:57:39.304457Z",
     "shell.execute_reply.started": "2022-06-07T02:57:39.294757Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:42.059622Z",
     "iopub.status.busy": "2022-06-07T02:57:42.059317Z",
     "iopub.status.idle": "2022-06-07T02:57:42.064691Z",
     "shell.execute_reply": "2022-06-07T02:57:42.063854Z",
     "shell.execute_reply.started": "2022-06-07T02:57:42.059591Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "valid_loader = DataLoader(final_validation_set, **valid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:45.505194Z",
     "iopub.status.busy": "2022-06-07T02:57:45.504873Z",
     "iopub.status.idle": "2022-06-07T02:57:45.570280Z",
     "shell.execute_reply": "2022-06-07T02:57:45.569402Z",
     "shell.execute_reply.started": "2022-06-07T02:57:45.505155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:57:48.975798Z",
     "iopub.status.busy": "2022-06-07T02:57:48.974974Z",
     "iopub.status.idle": "2022-06-07T02:58:20.162613Z",
     "shell.execute_reply": "2022-06-07T02:58:20.160339Z",
     "shell.execute_reply.started": "2022-06-07T02:57:48.975757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699aeca498664f1f8e6add9892e0ea5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4603abf9f2cf4d81bbe4b826c5c1ea00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:58:28.150023Z",
     "iopub.status.busy": "2022-06-07T02:58:28.149735Z",
     "iopub.status.idle": "2022-06-07T02:58:29.281405Z",
     "shell.execute_reply": "2022-06-07T02:58:29.280570Z",
     "shell.execute_reply.started": "2022-06-07T02:58:28.149988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6867, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:58:31.992114Z",
     "iopub.status.busy": "2022-06-07T02:58:31.991771Z",
     "iopub.status.idle": "2022-06-07T02:58:31.998910Z",
     "shell.execute_reply": "2022-06-07T02:58:31.997787Z",
     "shell.execute_reply.started": "2022-06-07T02:58:31.992056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:58:34.157030Z",
     "iopub.status.busy": "2022-06-07T02:58:34.156733Z",
     "iopub.status.idle": "2022-06-07T02:58:34.164220Z",
     "shell.execute_reply": "2022-06-07T02:58:34.163265Z",
     "shell.execute_reply.started": "2022-06-07T02:58:34.156999Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and fine-tuneing the BERT model using the SOCC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:58:37.999181Z",
     "iopub.status.busy": "2022-06-07T02:58:37.998868Z",
     "iopub.status.idle": "2022-06-07T02:58:38.012566Z",
     "shell.execute_reply": "2022-06-07T02:58:38.011627Z",
     "shell.execute_reply.started": "2022-06-07T02:58:37.999146Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:58:43.064505Z",
     "iopub.status.busy": "2022-06-07T02:58:43.063895Z",
     "iopub.status.idle": "2022-06-07T02:59:28.722375Z",
     "shell.execute_reply": "2022-06-07T02:59:28.721536Z",
     "shell.execute_reply.started": "2022-06-07T02:58:43.064466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 0.8718448281288147\n",
      "Training loss per 100 training steps: 0.42529961459412435\n",
      "Training loss per 100 training steps: 0.3253485243234654\n",
      "Training loss per 100 training steps: 0.2539540249382477\n",
      "Training loss per 100 training steps: 0.21394646742341672\n",
      "Training loss per 100 training steps: 0.19553941463147237\n",
      "Training loss epoch: 0.19205539854880857\n",
      "Training accuracy epoch: 0.9280739279681268\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:59:34.639413Z",
     "iopub.status.busy": "2022-06-07T02:59:34.638948Z",
     "iopub.status.idle": "2022-06-07T02:59:34.652897Z",
     "shell.execute_reply": "2022-06-07T02:59:34.651618Z",
     "shell.execute_reply.started": "2022-06-07T02:59:34.639368Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            \n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the BERT model on the test split of the SOCC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:59:37.488357Z",
     "iopub.status.busy": "2022-06-07T02:59:37.488035Z",
     "iopub.status.idle": "2022-06-07T02:59:41.369327Z",
     "shell.execute_reply": "2022-06-07T02:59:41.367816Z",
     "shell.execute_reply.started": "2022-06-07T02:59:37.488321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.7898760437965393\n",
      "Validation loss per 100 evaluation steps: 0.07695304542966648\n",
      "Validation loss per 100 evaluation steps: 0.08311045853002924\n",
      "Validation Loss: 0.07939997079224119\n",
      "Validation Accuracy: 0.9742784034994237\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:59:49.133648Z",
     "iopub.status.busy": "2022-06-07T02:59:49.133362Z",
     "iopub.status.idle": "2022-06-07T02:59:49.299270Z",
     "shell.execute_reply": "2022-06-07T02:59:49.298329Z",
     "shell.execute_reply.started": "2022-06-07T02:59:49.133615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.85      0.95      0.90      1402\n",
      "       False       0.99      0.97      0.98      9234\n",
      "\n",
      "    accuracy                           0.97     10636\n",
      "   macro avg       0.92      0.96      0.94     10636\n",
      "weighted avg       0.97      0.97      0.97     10636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "print(classification_report(labels, predictions, labels = list(labels_to_ids.keys()) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the BERT model on the HeyDay Validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T02:59:54.507668Z",
     "iopub.status.busy": "2022-06-07T02:59:54.507314Z",
     "iopub.status.idle": "2022-06-07T02:59:55.852436Z",
     "shell.execute_reply": "2022-06-07T02:59:55.851424Z",
     "shell.execute_reply.started": "2022-06-07T02:59:54.507627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.44423457980155945\n",
      "Validation Loss: 0.3378222560346503\n",
      "Validation Accuracy: 0.8931383090178608\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:00:00.849718Z",
     "iopub.status.busy": "2022-06-07T03:00:00.849245Z",
     "iopub.status.idle": "2022-06-07T03:00:00.895441Z",
     "shell.execute_reply": "2022-06-07T03:00:00.894433Z",
     "shell.execute_reply.started": "2022-06-07T03:00:00.849682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.31      0.72      0.43       145\n",
      "       False       0.98      0.89      0.93      2205\n",
      "\n",
      "    accuracy                           0.88      2350\n",
      "   macro avg       0.64      0.81      0.68      2350\n",
      "weighted avg       0.94      0.88      0.90      2350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, predictions, labels = list(labels_to_ids.keys()) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing into the CSV file and generating the final tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:00:15.746654Z",
     "iopub.status.busy": "2022-06-07T03:00:15.746063Z",
     "iopub.status.idle": "2022-06-07T03:00:15.758697Z",
     "shell.execute_reply": "2022-06-07T03:00:15.757730Z",
     "shell.execute_reply.started": "2022-06-07T03:00:15.746617Z"
    }
   },
   "outputs": [],
   "source": [
    "valset= pd.read_csv(\"../input/nertag/Heyday_validationdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:00:18.181921Z",
     "iopub.status.busy": "2022-06-07T03:00:18.181638Z",
     "iopub.status.idle": "2022-06-07T03:00:18.195461Z",
     "shell.execute_reply": "2022-06-07T03:00:18.194548Z",
     "shell.execute_reply.started": "2022-06-07T03:00:18.181888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted_NER_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>am</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>looking</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>166</td>\n",
       "      <td>30</td>\n",
       "      <td>I-SIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>166</td>\n",
       "      <td>inch</td>\n",
       "      <td>I-SIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>166</td>\n",
       "      <td>white</td>\n",
       "      <td>I-COLOUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>166</td>\n",
       "      <td>desk</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>166</td>\n",
       "      <td>set</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence_Index   Tokens Predicted_NER_Tags\n",
       "0                  0        I                  O\n",
       "1                  0       am                  O\n",
       "2                  0  looking                  O\n",
       "3                  0      for                  O\n",
       "4                  0        a                  O\n",
       "...              ...      ...                ...\n",
       "2345             166       30             I-SIZE\n",
       "2346             166     inch             I-SIZE\n",
       "2347             166    white           I-COLOUR\n",
       "2348             166     desk          I-PRODUCT\n",
       "2349             166      set          I-PRODUCT\n",
       "\n",
       "[2350 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:00:21.558836Z",
     "iopub.status.busy": "2022-06-07T03:00:21.558555Z",
     "iopub.status.idle": "2022-06-07T03:00:21.563648Z",
     "shell.execute_reply": "2022-06-07T03:00:21.562861Z",
     "shell.execute_reply.started": "2022-06-07T03:00:21.558804Z"
    }
   },
   "outputs": [],
   "source": [
    "token_list = valset.Tokens.values.tolist()\n",
    "sentence_list = valset.Sentence_Index.values.tolist()\n",
    "NER_list = valset.Predicted_NER_Tags.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:00:26.477209Z",
     "iopub.status.busy": "2022-06-07T03:00:26.476831Z",
     "iopub.status.idle": "2022-06-07T03:00:26.491031Z",
     "shell.execute_reply": "2022-06-07T03:00:26.490019Z",
     "shell.execute_reply.started": "2022-06-07T03:00:26.477165Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "rows = zip(sentence_list,token_list,NER_list,predictions)\n",
    "with open('Heyday_predvalidationdata.csv', \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(('Sentence_Index','Tokens','Predicted_NER_Tags','Predicted_Negation'))\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:46:45.227065Z",
     "iopub.status.busy": "2022-06-07T03:46:45.226779Z",
     "iopub.status.idle": "2022-06-07T03:46:45.241266Z",
     "shell.execute_reply": "2022-06-07T03:46:45.240306Z",
     "shell.execute_reply.started": "2022-06-07T03:46:45.227033Z"
    }
   },
   "outputs": [],
   "source": [
    "final_valset= pd.read_csv(\"../input/nertag/Heyday_final_predvalidationdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:46:48.002553Z",
     "iopub.status.busy": "2022-06-07T03:46:48.001964Z",
     "iopub.status.idle": "2022-06-07T03:46:48.015652Z",
     "shell.execute_reply": "2022-06-07T03:46:48.014678Z",
     "shell.execute_reply.started": "2022-06-07T03:46:48.002512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted_NER_Tags</th>\n",
       "      <th>Predicted_Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>am</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>looking</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>166</td>\n",
       "      <td>30</td>\n",
       "      <td>I-SIZE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>166</td>\n",
       "      <td>inch</td>\n",
       "      <td>I-SIZE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>166</td>\n",
       "      <td>white</td>\n",
       "      <td>I-COLOUR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>166</td>\n",
       "      <td>desk</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>166</td>\n",
       "      <td>set</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2350 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence_Index   Tokens Predicted_NER_Tags  Predicted_Negation\n",
       "0                  0        I                  O               False\n",
       "1                  0       am                  O               False\n",
       "2                  0  looking                  O               False\n",
       "3                  0      for                  O               False\n",
       "4                  0        a                  O               False\n",
       "...              ...      ...                ...                 ...\n",
       "2345             166       30             I-SIZE               False\n",
       "2346             166     inch             I-SIZE               False\n",
       "2347             166    white           I-COLOUR               False\n",
       "2348             166     desk          I-PRODUCT               False\n",
       "2349             166      set          I-PRODUCT               False\n",
       "\n",
       "[2350 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:47:20.148739Z",
     "iopub.status.busy": "2022-06-07T03:47:20.148478Z",
     "iopub.status.idle": "2022-06-07T03:47:20.163115Z",
     "shell.execute_reply": "2022-06-07T03:47:20.162039Z",
     "shell.execute_reply.started": "2022-06-07T03:47:20.148709Z"
    }
   },
   "outputs": [],
   "source": [
    "final_valset = final_valset.replace('I-','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:48:12.486761Z",
     "iopub.status.busy": "2022-06-07T03:48:12.486021Z",
     "iopub.status.idle": "2022-06-07T03:48:12.491694Z",
     "shell.execute_reply": "2022-06-07T03:48:12.490881Z",
     "shell.execute_reply.started": "2022-06-07T03:48:12.486722Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_final (row):\n",
    "   if row['Predicted_NER_Tags'] == 'O' :\n",
    "      return 'O'\n",
    "   if row['Predicted_NER_Tags'] != 'O' and row['Predicted_Negation'] == True :\n",
    "      return \"I-N-\"+row['Predicted_NER_Tags']\n",
    "   if row['Predicted_NER_Tags'] != 'O' and row['Predicted_Negation'] == False :\n",
    "      return \"I-\"+row['Predicted_NER_Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:48:14.807423Z",
     "iopub.status.busy": "2022-06-07T03:48:14.806619Z",
     "iopub.status.idle": "2022-06-07T03:48:14.889280Z",
     "shell.execute_reply": "2022-06-07T03:48:14.888235Z",
     "shell.execute_reply.started": "2022-06-07T03:48:14.807384Z"
    }
   },
   "outputs": [],
   "source": [
    "final_valset['final_label'] = final_valset.apply (lambda row: label_final(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:48:17.403613Z",
     "iopub.status.busy": "2022-06-07T03:48:17.403008Z",
     "iopub.status.idle": "2022-06-07T03:48:17.421807Z",
     "shell.execute_reply": "2022-06-07T03:48:17.420939Z",
     "shell.execute_reply.started": "2022-06-07T03:48:17.403574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted_NER_Tags</th>\n",
       "      <th>Predicted_Negation</th>\n",
       "      <th>final_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>am</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>looking</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>166</td>\n",
       "      <td>30</td>\n",
       "      <td>SIZE</td>\n",
       "      <td>False</td>\n",
       "      <td>I-SIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>166</td>\n",
       "      <td>inch</td>\n",
       "      <td>SIZE</td>\n",
       "      <td>False</td>\n",
       "      <td>I-SIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>166</td>\n",
       "      <td>white</td>\n",
       "      <td>COLOUR</td>\n",
       "      <td>False</td>\n",
       "      <td>I-COLOUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>166</td>\n",
       "      <td>desk</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>False</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>166</td>\n",
       "      <td>set</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>False</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2350 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence_Index   Tokens Predicted_NER_Tags  Predicted_Negation  \\\n",
       "0                  0        I                  O               False   \n",
       "1                  0       am                  O               False   \n",
       "2                  0  looking                  O               False   \n",
       "3                  0      for                  O               False   \n",
       "4                  0        a                  O               False   \n",
       "...              ...      ...                ...                 ...   \n",
       "2345             166       30               SIZE               False   \n",
       "2346             166     inch               SIZE               False   \n",
       "2347             166    white             COLOUR               False   \n",
       "2348             166     desk            PRODUCT               False   \n",
       "2349             166      set            PRODUCT               False   \n",
       "\n",
       "     final_label  \n",
       "0              O  \n",
       "1              O  \n",
       "2              O  \n",
       "3              O  \n",
       "4              O  \n",
       "...          ...  \n",
       "2345      I-SIZE  \n",
       "2346      I-SIZE  \n",
       "2347    I-COLOUR  \n",
       "2348   I-PRODUCT  \n",
       "2349   I-PRODUCT  \n",
       "\n",
       "[2350 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_valset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:48:58.156874Z",
     "iopub.status.busy": "2022-06-07T03:48:58.156604Z",
     "iopub.status.idle": "2022-06-07T03:48:58.170614Z",
     "shell.execute_reply": "2022-06-07T03:48:58.169524Z",
     "shell.execute_reply.started": "2022-06-07T03:48:58.156843Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(\"../input/nertag/clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:52:54.365979Z",
     "iopub.status.busy": "2022-06-07T03:52:54.365723Z",
     "iopub.status.idle": "2022-06-07T03:52:54.378414Z",
     "shell.execute_reply": "2022-06-07T03:52:54.377507Z",
     "shell.execute_reply.started": "2022-06-07T03:52:54.365950Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.replace('B-','I-', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:52:56.805987Z",
     "iopub.status.busy": "2022-06-07T03:52:56.805392Z",
     "iopub.status.idle": "2022-06-07T03:52:56.821904Z",
     "shell.execute_reply": "2022-06-07T03:52:56.821145Z",
     "shell.execute_reply.started": "2022-06-07T03:52:56.805942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>30</td>\n",
       "      <td>I-SIZE</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>inch</td>\n",
       "      <td>I-SIZE</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>white</td>\n",
       "      <td>I-COLOUR</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>desk</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>set</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokens       Tags  sentence\n",
       "0           I          O         0\n",
       "1          am          O         0\n",
       "2     looking          O         0\n",
       "3         for          O         0\n",
       "4           a          O         0\n",
       "...       ...        ...       ...\n",
       "2345       30     I-SIZE       166\n",
       "2346     inch     I-SIZE       166\n",
       "2347    white   I-COLOUR       166\n",
       "2348     desk  I-PRODUCT       166\n",
       "2349      set  I-PRODUCT       166\n",
       "\n",
       "[2350 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:53:02.790074Z",
     "iopub.status.busy": "2022-06-07T03:53:02.789787Z",
     "iopub.status.idle": "2022-06-07T03:53:02.795278Z",
     "shell.execute_reply": "2022-06-07T03:53:02.794282Z",
     "shell.execute_reply.started": "2022-06-07T03:53:02.790044Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_list = clean_data.Tags.values.tolist()\n",
    "pred_list = final_valset.final_label.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T03:53:05.097656Z",
     "iopub.status.busy": "2022-06-07T03:53:05.097118Z",
     "iopub.status.idle": "2022-06-07T03:53:05.154629Z",
     "shell.execute_reply": "2022-06-07T03:53:05.153792Z",
     "shell.execute_reply.started": "2022-06-07T03:53:05.097617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  I-ATTRIBUTE       0.65      0.72      0.68       148\n",
      "     I-COLOUR       0.86      0.65      0.74        48\n",
      "   I-MATERIAL       1.00      0.58      0.73        33\n",
      "I-N-ATTRIBUTE       0.85      0.57      0.68        98\n",
      "   I-N-COLOUR       1.00      0.25      0.40         8\n",
      " I-N-MATERIAL       0.50      0.25      0.33         4\n",
      "    I-N-PRICE       0.00      0.00      0.00         3\n",
      "  I-N-PRODUCT       0.45      0.48      0.47        21\n",
      "    I-N-SHAPE       0.00      0.00      0.00         2\n",
      "     I-N-SIZE       0.34      0.56      0.43        18\n",
      "  I-N-TEXTURE       0.00      0.00      0.00         4\n",
      "      I-PRICE       1.00      0.25      0.40        12\n",
      "    I-PRODUCT       0.92      0.87      0.90       320\n",
      "      I-SHAPE       1.00      0.44      0.62         9\n",
      "       I-SIZE       0.90      0.85      0.88       166\n",
      "    I-TEXTURE       1.00      0.12      0.22         8\n",
      "            O       0.92      0.98      0.95      1448\n",
      "\n",
      "     accuracy                           0.89      2350\n",
      "    macro avg       0.67      0.45      0.50      2350\n",
      " weighted avg       0.89      0.89      0.88      2350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(clean_list, pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T07:00:06.325190Z",
     "iopub.status.busy": "2022-06-06T07:00:06.324786Z",
     "iopub.status.idle": "2022-06-06T07:00:06.633913Z",
     "shell.execute_reply": "2022-06-06T07:00:06.633088Z",
     "shell.execute_reply.started": "2022-06-06T07:00:06.325149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('black', 'False')\n",
      "('gloss', 'False')\n",
      "('33', 'False')\n",
      "('inch', 'False')\n",
      "('fireclay', 'False')\n",
      "('apron', 'False')\n",
      "('sink', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('pre', 'False')\n",
      "('workout', 'False')\n",
      "('Pump', 'False')\n",
      "('addict', 'False')\n",
      "('instead', 'False')\n",
      "('of', 'False')\n",
      "('Karbolyn', 'False')\n",
      "('Hydrate', 'False')\n",
      "('Wich', 'False')\n",
      "('one', 'False')\n",
      "('is', 'False')\n",
      "('better?', 'False')\n",
      "('i', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('48', 'False')\n",
      "('inch', 'False')\n",
      "('glass', 'False')\n",
      "('sliding', 'False')\n",
      "('goof', 'False')\n",
      "('and', 'False')\n",
      "('a', 'False')\n",
      "('shower', 'False')\n",
      "('pan', 'False')\n",
      "('system', 'False')\n",
      "('for', 'False')\n",
      "('500.99', 'False')\n",
      "('or', 'False')\n",
      "('less', 'False')\n",
      "('Hello,', 'False')\n",
      "('do', 'False')\n",
      "('any', 'False')\n",
      "('of', 'False')\n",
      "('your', 'False')\n",
      "('free', 'False')\n",
      "('standing', 'False')\n",
      "('tubs', 'False')\n",
      "('have', 'False')\n",
      "('a', 'False')\n",
      "('matte', 'False')\n",
      "('white', 'False')\n",
      "('finish', 'False')\n",
      "('instead', 'False')\n",
      "('of', 'False')\n",
      "('a', 'False')\n",
      "('glossy', 'False')\n",
      "('finish?', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('24', 'False')\n",
      "('inch', 'False')\n",
      "('white', 'False')\n",
      "('mirror', 'False')\n",
      "('that', 'False')\n",
      "('is', 'False')\n",
      "('freestanding', 'False')\n",
      "('and', 'False')\n",
      "('reasonably', 'False')\n",
      "('priced.', 'False')\n",
      "('Does', 'False')\n",
      "('the', 'False')\n",
      "('linen', 'False')\n",
      "('add', 'False')\n",
      "('cotton', 'False')\n",
      "('duvet', 'False')\n",
      "('cover', 'False')\n",
      "('come', 'False')\n",
      "('in', 'False')\n",
      "('King?', 'False')\n",
      "('I', 'False')\n",
      "('saw', 'False')\n",
      "('it', 'False')\n",
      "('in', 'False')\n",
      "('the', 'False')\n",
      "('store', 'False')\n",
      "('but', 'False')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('see', 'True')\n",
      "('the', 'True')\n",
      "('king', 'True')\n",
      "('size', 'True')\n",
      "('online', 'True')\n",
      "('?', 'False')\n",
      "('Hi', 'False')\n",
      "('there.', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('to', 'False')\n",
      "('buy', 'False')\n",
      "('some', 'False')\n",
      "('throw', 'False')\n",
      "('blankets.', 'False')\n",
      "('Your', 'False')\n",
      "('website', 'False')\n",
      "('states', 'False')\n",
      "('that', 'False')\n",
      "('the', 'False')\n",
      "('underside', 'False')\n",
      "('of', 'False')\n",
      "('the', 'False')\n",
      "('Boucle', 'False')\n",
      "('wool-like', 'False')\n",
      "('throw', 'False')\n",
      "('is', 'False')\n",
      "('very', 'False')\n",
      "('soft.', 'False')\n",
      "('I', 'False')\n",
      "('would', 'False')\n",
      "('like', 'False')\n",
      "('to', 'False')\n",
      "('know', 'False')\n",
      "('if', 'False')\n",
      "('the', 'False')\n",
      "('wool-like', 'False')\n",
      "('top', 'False')\n",
      "('side', 'False')\n",
      "('is', 'False')\n",
      "('soft', 'False')\n",
      "('as', 'False')\n",
      "('well,', 'False')\n",
      "('or', 'False')\n",
      "('if', 'False')\n",
      "('it', 'False')\n",
      "('is', 'False')\n",
      "('scratchy.', 'False')\n",
      "('I', 'False')\n",
      "('have', 'False')\n",
      "('hypersensitive', 'False')\n",
      "('skin', 'False')\n",
      "('and', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('blanket', 'False')\n",
      "('that', 'False')\n",
      "('will', 'False')\n",
      "('not', 'False')\n",
      "('irritate', 'True')\n",
      "('me.', 'True')\n",
      "('Thanks.', 'False')\n",
      "('Long', 'False')\n",
      "('Sherpa', 'False')\n",
      "('jacket', 'False')\n",
      "('dark', 'False')\n",
      "('brown', 'False')\n",
      "('why', 'False')\n",
      "(\"can't\", 'False')\n",
      "('I', 'True')\n",
      "('find', 'True')\n",
      "('it?', 'True')\n",
      "('Hello.', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('soft', 'False')\n",
      "('Open', 'False')\n",
      "('face', 'False')\n",
      "('cardigan', 'False')\n",
      "('w', 'False')\n",
      "('no', 'False')\n",
      "('buttons.', 'True')\n",
      "('hi', 'False')\n",
      "('do', 'False')\n",
      "('you', 'False')\n",
      "('carry', 'False')\n",
      "('any', 'False')\n",
      "('oval', 'False')\n",
      "('tubs', 'False')\n",
      "('in', 'False')\n",
      "('a', 'False')\n",
      "('matte', 'False')\n",
      "('white', 'False')\n",
      "('finish', 'False')\n",
      "('or', 'False')\n",
      "('not', 'False')\n",
      "('too', 'True')\n",
      "('much', 'True')\n",
      "('of', 'True')\n",
      "('gloss?', 'True')\n",
      "('i', 'False')\n",
      "('know', 'False')\n",
      "('they', 'False')\n",
      "('make', 'False')\n",
      "('solid', 'False')\n",
      "('surface', 'False')\n",
      "('but', 'False')\n",
      "('higher', 'False')\n",
      "('prices.', 'False')\n",
      "('thank', 'False')\n",
      "('you', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('not', 'False')\n",
      "('have', 'True')\n",
      "('alcove', 'True')\n",
      "('shower', 'True')\n",
      "('walls?', 'True')\n",
      "('Hi', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('considering', 'False')\n",
      "('a', 'False')\n",
      "('bathtub', 'False')\n",
      "('swivel', 'False')\n",
      "('panel.', 'False')\n",
      "('I', 'False')\n",
      "('assume', 'False')\n",
      "('it', 'False')\n",
      "(\"doesn't\", 'False')\n",
      "('matter', 'True')\n",
      "('which', 'True')\n",
      "('way', 'True')\n",
      "('the', 'True')\n",
      "('bathtub', 'True')\n",
      "('is', 'True')\n",
      "('facing?', 'True')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('alcove', 'False')\n",
      "('shower', 'False')\n",
      "('base', 'False')\n",
      "('.', 'False')\n",
      "('not', 'False')\n",
      "('so', 'True')\n",
      "('much', 'True')\n",
      "('$', 'True')\n",
      "('lol', 'True')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('a', 'False')\n",
      "('vanity', 'False')\n",
      "('tops', 'False')\n",
      "('or', 'False')\n",
      "('wall', 'False')\n",
      "('mount', 'False')\n",
      "('sink', 'False')\n",
      "('without', 'False')\n",
      "('faucet', 'True')\n",
      "('holes?', 'True')\n",
      "('Hi!!', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('60\"', 'False')\n",
      "('wide', 'False')\n",
      "('tub', 'False')\n",
      "('but', 'False')\n",
      "('a', 'False')\n",
      "('soaker', 'False')\n",
      "('type', 'False')\n",
      "('thats', 'False')\n",
      "('deeper', 'False')\n",
      "('than', 'False')\n",
      "('a', 'False')\n",
      "('regular', 'False')\n",
      "('tub', 'False')\n",
      "('do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('this', 'False')\n",
      "('type?', 'False')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('see', 'True')\n",
      "('anything', 'True')\n",
      "('deep', 'True')\n",
      "('enough', 'True')\n",
      "('on', 'True')\n",
      "('your', 'True')\n",
      "('site', 'True')\n",
      "('Ok', 'False')\n",
      "('thanks.', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('pure', 'False')\n",
      "('white', 'False')\n",
      "('alcove', 'False')\n",
      "('bathtub,', 'False')\n",
      "('not', 'False')\n",
      "('American', 'True')\n",
      "('standard', 'True')\n",
      "('or', 'True')\n",
      "('any', 'True')\n",
      "('off', 'True')\n",
      "('whites.', 'True')\n",
      "('Is', 'False')\n",
      "('there', 'False')\n",
      "('one', 'False')\n",
      "('you', 'False')\n",
      "('could', 'False')\n",
      "('recommend', 'False')\n",
      "('Hi,', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('a', 'False')\n",
      "('navy', 'False')\n",
      "('mirror', 'False')\n",
      "('size', 'False')\n",
      "('60x31.', 'False')\n",
      "('You', 'False')\n",
      "('have', 'False')\n",
      "('it', 'False')\n",
      "('for', 'False')\n",
      "('the', 'False')\n",
      "('gold', 'False')\n",
      "('and', 'False')\n",
      "('black', 'False')\n",
      "('but', 'False')\n",
      "('i', 'False')\n",
      "(\"don't\", 'False')\n",
      "('want', 'True')\n",
      "('it', 'True')\n",
      "('for', 'True')\n",
      "('the', 'True')\n",
      "('navy.', 'True')\n",
      "('Hi,', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('floating', 'False')\n",
      "('vanity', 'False')\n",
      "('with', 'False')\n",
      "('integrated', 'False')\n",
      "('sink', 'False')\n",
      "('&', 'False')\n",
      "('counter', 'False')\n",
      "('top', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('drill', 'True')\n",
      "('holes', 'True')\n",
      "('for', 'True')\n",
      "('the', 'True')\n",
      "('faucet', 'True')\n",
      "('as', 'True')\n",
      "('our', 'True')\n",
      "('faucets', 'True')\n",
      "('are', 'True')\n",
      "('wall', 'True')\n",
      "('mounted.', 'True')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('sell', 'False')\n",
      "('theM', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('soaker', 'False')\n",
      "('tub', 'False')\n",
      "('but', 'False')\n",
      "('do', 'False')\n",
      "('not', 'False')\n",
      "('want', 'True')\n",
      "('stand', 'True')\n",
      "('alone.', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('replacing', 'False')\n",
      "('my', 'False')\n",
      "('oval', 'False')\n",
      "('jacuzzi', 'False')\n",
      "('Where', 'False')\n",
      "('is', 'False')\n",
      "('the', 'False')\n",
      "('mirror', 'False')\n",
      "('on', 'False')\n",
      "('here.', 'False')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('want', 'True')\n",
      "('linen', 'True')\n",
      "('cabinet', 'True')\n",
      "('Hello,', 'False')\n",
      "('I', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('standup', 'False')\n",
      "('shower', 'False')\n",
      "('door', 'False')\n",
      "('only,', 'False')\n",
      "('no', 'False')\n",
      "('side', 'True')\n",
      "('panels.', 'True')\n",
      "('41', 'False')\n",
      "('inches', 'False')\n",
      "('wide', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('double', 'False')\n",
      "('sink', 'False')\n",
      "('kitchen', 'False')\n",
      "('close', 'False')\n",
      "('to', 'False')\n",
      "('52', 'False')\n",
      "('inches', 'False')\n",
      "('no', 'False')\n",
      "('bigger', 'True')\n",
      "('with', 'True')\n",
      "('countertop', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('bypass', 'False')\n",
      "('shower', 'False')\n",
      "('doors', 'False')\n",
      "('in', 'False')\n",
      "('chrome', 'False')\n",
      "('with', 'False')\n",
      "('clear', 'False')\n",
      "('glass.', 'False')\n",
      "('The', 'False')\n",
      "('opening', 'False')\n",
      "('would', 'False')\n",
      "('be', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('59\"', 'False')\n",
      "('width', 'False')\n",
      "('and', 'False')\n",
      "('the', 'False')\n",
      "('height', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('is', 'False')\n",
      "('76\".', 'False')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('want', 'True')\n",
      "('any', 'True')\n",
      "('rubber', 'True')\n",
      "('seals', 'True')\n",
      "('around', 'True')\n",
      "('the', 'True')\n",
      "('glass', 'True')\n",
      "('doors.', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('at', 'False')\n",
      "('the', 'False')\n",
      "('34\"x34\"', 'False')\n",
      "('shower', 'False')\n",
      "('kit', 'False')\n",
      "('with', 'False')\n",
      "('door,', 'False')\n",
      "('walls,', 'False')\n",
      "('base', 'False')\n",
      "('and', 'False')\n",
      "('glass', 'False')\n",
      "('shelves.', 'False')\n",
      "('Can', 'False')\n",
      "('the', 'False')\n",
      "('2\"', 'False')\n",
      "('backsplash,', 'False')\n",
      "('on', 'False')\n",
      "('the', 'False')\n",
      "('60\"', 'False')\n",
      "('single', 'False')\n",
      "('sink', 'False')\n",
      "('countertop,', 'False')\n",
      "('be', 'False')\n",
      "('removed?', 'False')\n",
      "('Or', 'False')\n",
      "('is', 'False')\n",
      "('the', 'False')\n",
      "('counter', 'False')\n",
      "('and', 'False')\n",
      "('backsplash', 'False')\n",
      "('one', 'False')\n",
      "('piece?', 'False')\n",
      "('If', 'False')\n",
      "('so,', 'False')\n",
      "('do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('a', 'False')\n",
      "('single', 'False')\n",
      "('sink,', 'False')\n",
      "('white', 'False')\n",
      "('60\"', 'False')\n",
      "('vanity', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('backsplash', 'True')\n",
      "('piece?', 'True')\n",
      "(\"We're\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('60', 'False')\n",
      "('inch', 'False')\n",
      "('left', 'False')\n",
      "('drain', 'False')\n",
      "('alcove', 'False')\n",
      "('tub', 'False')\n",
      "('which', 'False')\n",
      "('is', 'False')\n",
      "('a', 'False')\n",
      "('soaker', 'False')\n",
      "('tub', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('more', 'True')\n",
      "('than', 'True')\n",
      "('15\"', 'True')\n",
      "('height.', 'True')\n",
      "('In', 'False')\n",
      "('white.', 'False')\n",
      "('just', 'False')\n",
      "('need', 'False')\n",
      "('glass', 'False')\n",
      "('doors', 'False')\n",
      "('no', 'False')\n",
      "('end', 'True')\n",
      "('glass', 'True')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('Chrome', 'False')\n",
      "('column-style', 'False')\n",
      "('showerhead', 'False')\n",
      "('with', 'False')\n",
      "('body', 'False')\n",
      "('jets', 'False')\n",
      "('and', 'False')\n",
      "('rain', 'False')\n",
      "('showerhead', 'False')\n",
      "('i', 'False')\n",
      "('live', 'False')\n",
      "('in', 'False')\n",
      "('__location__', 'False')\n",
      "('and', 'False')\n",
      "('i', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('an', 'False')\n",
      "('acrylic', 'False')\n",
      "('(', 'False')\n",
      "('preference', 'False')\n",
      "(')', 'False')\n",
      "('or', 'False')\n",
      "('fibreglass', 'False')\n",
      "('shower', 'False')\n",
      "('base.', 'False')\n",
      "('I', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('50', 'False')\n",
      "('inch', 'False')\n",
      "('wide', 'False')\n",
      "('by', 'False')\n",
      "('34', 'False')\n",
      "('inch', 'False')\n",
      "('deep', 'False')\n",
      "('with', 'False')\n",
      "('a', 'False')\n",
      "('5', 'False')\n",
      "('inch', 'False')\n",
      "('single', 'False')\n",
      "('threshold', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('tub/shower', 'False')\n",
      "('righthand', 'False')\n",
      "('and', 'False')\n",
      "('one', 'False')\n",
      "('lefthand,', 'False')\n",
      "('what', 'False')\n",
      "('are', 'False')\n",
      "('my', 'False')\n",
      "('options?', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('freestanding', 'False')\n",
      "('tub', 'False')\n",
      "('with', 'False')\n",
      "('a', 'False')\n",
      "('bathing', 'False')\n",
      "('well', 'False')\n",
      "('bottom', 'False')\n",
      "('length', 'False')\n",
      "('of', 'False')\n",
      "('45', 'False')\n",
      "('inches', 'False')\n",
      "('minimum', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('round', 'False')\n",
      "('shower', 'False')\n",
      "('around', 'False')\n",
      "('73', 'False')\n",
      "('inches', 'False')\n",
      "('high', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('to', 'False')\n",
      "('buy', 'False')\n",
      "('a', 'False')\n",
      "('42\"', 'False')\n",
      "('gazebo', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('more', 'True')\n",
      "('than', 'True')\n",
      "('21\"', 'True')\n",
      "('depth', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('shelves', 'False')\n",
      "('that', 'False')\n",
      "('mount', 'False')\n",
      "('to', 'False')\n",
      "('a', 'False')\n",
      "('wall,', 'False')\n",
      "('no', 'False')\n",
      "('screw', 'True')\n",
      "('30', 'True')\n",
      "('inches', 'True')\n",
      "('__brand__', 'False')\n",
      "('bathtub', 'False')\n",
      "('58', 'False')\n",
      "('in.', 'False')\n",
      "('x', 'False')\n",
      "('5', 'False')\n",
      "('in.', 'False')\n",
      "('4-Jet', 'False')\n",
      "('High', 'False')\n",
      "('Pressure', 'False')\n",
      "('Shower', 'False')\n",
      "('Panel', 'False')\n",
      "('System', 'False')\n",
      "('with', 'False')\n",
      "('Square', 'False')\n",
      "('Rain', 'False')\n",
      "('Shower', 'False')\n",
      "('Head', 'False')\n",
      "('and', 'False')\n",
      "('Tub', 'False')\n",
      "('Filler', 'False')\n",
      "('in', 'False')\n",
      "('Matte', 'False')\n",
      "('Black', 'False')\n",
      "('Model', 'False')\n",
      "('Yes,', 'False')\n",
      "('I', 'False')\n",
      "('bought', 'False')\n",
      "('a', 'False')\n",
      "('tub', 'False')\n",
      "('from', 'False')\n",
      "('you,', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('adjustable', 'False')\n",
      "('screw', 'False')\n",
      "('that', 'False')\n",
      "('attaches', 'False')\n",
      "('to', 'False')\n",
      "('the', 'False')\n",
      "('plug.', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('60', 'False')\n",
      "('inch', 'False')\n",
      "('white', 'False')\n",
      "('bathtub', 'False')\n",
      "('that', 'False')\n",
      "('is', 'False')\n",
      "('freestanding', 'False')\n",
      "('and', 'False')\n",
      "('reasonably', 'False')\n",
      "('priced', 'False')\n",
      "(\"i'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('unflavored', 'False')\n",
      "('mass', 'False')\n",
      "('gainer', 'False')\n",
      "('protein', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('a', 'False')\n",
      "('wall', 'False')\n",
      "('mount', 'False')\n",
      "('sink', 'False')\n",
      "('without', 'False')\n",
      "('a', 'True')\n",
      "('faucet', 'True')\n",
      "('hole', 'False')\n",
      "('Just', 'False')\n",
      "('shower', 'False')\n",
      "('base', 'False')\n",
      "('without', 'False')\n",
      "('walls', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('shower', 'False')\n",
      "('unit,', 'False')\n",
      "('60\"', 'False')\n",
      "('wide', 'False')\n",
      "('by', 'False')\n",
      "('42\"', 'False')\n",
      "('deep,', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('seat', 'True')\n",
      "('and', 'True')\n",
      "('no', 'False')\n",
      "('top', 'True')\n",
      "('luggage', 'False')\n",
      "('without', 'False')\n",
      "('wheels', 'False')\n",
      "('I', 'False')\n",
      "('found', 'False')\n",
      "('a', 'False')\n",
      "('vanity', 'False')\n",
      "('top', 'False')\n",
      "('I', 'False')\n",
      "('love', 'False')\n",
      "('but', 'False')\n",
      "('it', 'False')\n",
      "('has', 'False')\n",
      "('only', 'False')\n",
      "('one', 'False')\n",
      "('hole', 'False')\n",
      "('for', 'False')\n",
      "('taps', 'False')\n",
      "('and', 'False')\n",
      "('that', 'False')\n",
      "(\"doesn't\", 'False')\n",
      "('suit', 'True')\n",
      "('our', 'True')\n",
      "('needs', 'True')\n",
      "('curbless', 'False')\n",
      "('shower', 'False')\n",
      "('Walk', 'False')\n",
      "('in', 'False')\n",
      "('tubs', 'False')\n",
      "('for', 'False')\n",
      "('seniors', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('shower', 'False')\n",
      "('door', 'False')\n",
      "('about', 'False')\n",
      "('30', 'False')\n",
      "('inches', 'False')\n",
      "('I', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('toilet', 'False')\n",
      "('that', 'False')\n",
      "('is', 'False')\n",
      "('only', 'False')\n",
      "('28', 'False')\n",
      "('inches', 'False')\n",
      "('high', 'False')\n",
      "('Hi,', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('bathroom', 'False')\n",
      "('LED', 'False')\n",
      "('mirrors', 'False')\n",
      "('that', 'False')\n",
      "('are', 'False')\n",
      "('24', 'False')\n",
      "('inch.', 'False')\n",
      "('That', 'False')\n",
      "('are', 'False')\n",
      "('hard', 'False')\n",
      "('wired', 'False')\n",
      "('and', 'False')\n",
      "('can', 'False')\n",
      "('be', 'False')\n",
      "('turned', 'False')\n",
      "('on', 'False')\n",
      "('from', 'False')\n",
      "('the', 'False')\n",
      "('mirror', 'False')\n",
      "('Denim', 'False')\n",
      "('skirts?', 'False')\n",
      "('touch', 'False')\n",
      "('of', 'False')\n",
      "('linen', 'False')\n",
      "('buttoned', 'False')\n",
      "('skirt', 'False')\n",
      "('in', 'False')\n",
      "('patterned', 'False')\n",
      "('white', 'False')\n",
      "('colour', 'False')\n",
      "('Base', 'False')\n",
      "('cabinet', 'False')\n",
      "('42', 'False')\n",
      "('inches', 'False')\n",
      "('long', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('the', 'False')\n",
      "('sweater', 'False')\n",
      "('in', 'False')\n",
      "('medium?', 'False')\n",
      "('Hi.', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('sheer', 'False')\n",
      "('curtains', 'False')\n",
      "('which', 'False')\n",
      "('I', 'False')\n",
      "('can', 'False')\n",
      "('place', 'False')\n",
      "('on', 'False')\n",
      "('hooks', 'False')\n",
      "('instead', 'False')\n",
      "('of', 'False')\n",
      "('a', 'False')\n",
      "('rod', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('Grey', 'False')\n",
      "('drapery', 'False')\n",
      "('panels', 'False')\n",
      "('10', 'False')\n",
      "('feet', 'False')\n",
      "('in', 'False')\n",
      "('length', 'False')\n",
      "('twik', 'False')\n",
      "('white', 'False')\n",
      "('sleeveless', 'False')\n",
      "('button', 'False')\n",
      "('closure', 'False')\n",
      "('top', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('waterproof', 'False')\n",
      "('queen', 'False')\n",
      "('size', 'False')\n",
      "('mattress', 'False')\n",
      "('protectors', 'False')\n",
      "('for', 'False')\n",
      "('over', 'False')\n",
      "('18', 'False')\n",
      "('inch', 'False')\n",
      "('mattresses?', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('Mercerized', 'False')\n",
      "('cotton', 'False')\n",
      "('high-performance', 'False')\n",
      "('T-shirt', 'False')\n",
      "('in', 'False')\n",
      "('size', 'False')\n",
      "('medium', 'False')\n",
      "('Are', 'False')\n",
      "('the', 'False')\n",
      "('round', 'False')\n",
      "('velvet', 'False')\n",
      "('floor', 'False')\n",
      "('cushions', 'False')\n",
      "('available', 'False')\n",
      "('in', 'False')\n",
      "('store?', 'False')\n",
      "('I', 'False')\n",
      "('would', 'False')\n",
      "('like', 'False')\n",
      "('the', 'False')\n",
      "('sweater', 'False')\n",
      "('as', 'False')\n",
      "('well', 'False')\n",
      "('as', 'False')\n",
      "('the', 'False')\n",
      "('icons', 'False')\n",
      "('pencil', 'False')\n",
      "('skirt', 'False')\n",
      "('in', 'False')\n",
      "('green', 'False')\n",
      "('Sleeveless', 'False')\n",
      "('sweater', 'False')\n",
      "('Unflavored', 'False')\n",
      "('unsweetened', 'False')\n",
      "('do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('the', 'False')\n",
      "('stainless', 'False')\n",
      "('steel', 'False')\n",
      "('shaker', 'False')\n",
      "('cups', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('flavor', 'False')\n",
      "('powders', 'False')\n",
      "('which', 'False')\n",
      "('I', 'False')\n",
      "('can', 'False')\n",
      "('use', 'False')\n",
      "('in', 'False')\n",
      "('yoghurts', 'False')\n",
      "('for', 'False')\n",
      "('example', 'False')\n",
      "('Hi,', 'False')\n",
      "('do', 'False')\n",
      "('you', 'False')\n",
      "('sell', 'False')\n",
      "('fingerless', 'False')\n",
      "('gloves', 'False')\n",
      "('please', 'False')\n",
      "('Need', 'False')\n",
      "('an', 'False')\n",
      "('inexpensive', 'False')\n",
      "('thermostatic', 'False')\n",
      "('shower', 'False')\n",
      "('set', 'False')\n",
      "('with', 'False')\n",
      "('an', 'False')\n",
      "('extra', 'False')\n",
      "('outlet', 'False')\n",
      "('for', 'False')\n",
      "('bidet.', 'False')\n",
      "('Can', 'False')\n",
      "('you', 'False')\n",
      "('suggest', 'False')\n",
      "('a', 'False')\n",
      "('couple.', 'False')\n",
      "('hi,', 'False')\n",
      "('can', 'False')\n",
      "('I', 'False')\n",
      "('put', 'False')\n",
      "('a', 'False')\n",
      "('tankless', 'False')\n",
      "('toilet', 'False')\n",
      "('into', 'False')\n",
      "('a', 'False')\n",
      "('2\"x', 'False')\n",
      "('4\"', 'False')\n",
      "('wall?', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('left', 'False')\n",
      "('offset', 'False')\n",
      "('vanity', 'False')\n",
      "('set', 'False')\n",
      "('up', 'False')\n",
      "('to', 'False')\n",
      "('48', 'False')\n",
      "('inches', 'False')\n",
      "('wide,', 'False')\n",
      "('white,', 'False')\n",
      "('brushed', 'False')\n",
      "('nickel', 'False')\n",
      "('hardware', 'False')\n",
      "('seamless', 'False')\n",
      "('undermount', 'False')\n",
      "('Touchless', 'False')\n",
      "('kitchen', 'False')\n",
      "('faucet', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('bowl', 'False')\n",
      "('with', 'False')\n",
      "('pattern', 'False')\n",
      "('LESS', 'False')\n",
      "('than', 'False')\n",
      "('5', 'False')\n",
      "('inches', 'False')\n",
      "('deep.', 'False')\n",
      "('Can', 'False')\n",
      "('be', 'False')\n",
      "('7', 'False')\n",
      "('inches', 'False')\n",
      "('wide', 'False')\n",
      "('Looking', 'False')\n",
      "('shower', 'False')\n",
      "('door', 'False')\n",
      "('frameless', 'False')\n",
      "('of', 'False')\n",
      "('60', 'False')\n",
      "('inch', 'False')\n",
      "('standing', 'False')\n",
      "('shower', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('sell', 'False')\n",
      "('beige', 'False')\n",
      "('toilets.', 'False')\n",
      "('Bone', 'False')\n",
      "('and', 'False')\n",
      "('buscuit', 'False')\n",
      "('are', 'False')\n",
      "('too', 'False')\n",
      "('light', 'False')\n",
      "('in', 'False')\n",
      "('colour', 'False')\n",
      "(\"We're\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('shower', 'False')\n",
      "('door', 'False')\n",
      "('set', 'False')\n",
      "('greater', 'False')\n",
      "('than', 'False')\n",
      "('70', 'False')\n",
      "('inches', 'False')\n",
      "('wide', 'False')\n",
      "('18', 'False')\n",
      "('inch', 'False')\n",
      "('deep', 'False')\n",
      "('by', 'False')\n",
      "('36', 'False')\n",
      "('inches', 'False')\n",
      "('long', 'False')\n",
      "('brown', 'False')\n",
      "('freestanding', 'False')\n",
      "('vanity', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('36', 'False')\n",
      "('inch', 'False')\n",
      "('vanity', 'False')\n",
      "('with', 'False')\n",
      "('granite', 'False')\n",
      "('top', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('bathroom', 'False')\n",
      "('mirrors', 'False')\n",
      "('black', 'False')\n",
      "('framed', 'False')\n",
      "('in', 'False')\n",
      "('rectangular', 'False')\n",
      "('and', 'False')\n",
      "('oval', 'False')\n",
      "('looking', 'False')\n",
      "('at', 'False')\n",
      "('36', 'False')\n",
      "('inch', 'False')\n",
      "('medicine', 'False')\n",
      "('cabinet', 'False')\n",
      "('for', 'False')\n",
      "('$399', 'False')\n",
      "('.', 'False')\n",
      "('is', 'False')\n",
      "('it', 'False')\n",
      "('recessed', 'False')\n",
      "('able', 'False')\n",
      "('to', 'False')\n",
      "('fit', 'False')\n",
      "('into', 'False')\n",
      "('wall', 'False')\n",
      "('as', 'False')\n",
      "('a', 'False')\n",
      "('flush', 'False')\n",
      "('mount?', 'False')\n",
      "('Vessel', 'False')\n",
      "('bag', 'False')\n",
      "('in', 'False')\n",
      "('goldish', 'False')\n",
      "('color', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('protein', 'False')\n",
      "('powder', 'False')\n",
      "('no', 'False')\n",
      "('carb', 'True')\n",
      "('no', 'False')\n",
      "('suger', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('brand', 'False')\n",
      "('new', 'False')\n",
      "('to', 'False')\n",
      "('fat', 'False')\n",
      "('burners,', 'False')\n",
      "('I', 'False')\n",
      "('want', 'False')\n",
      "('to', 'False')\n",
      "('know', 'False')\n",
      "('a', 'False')\n",
      "('good', 'False')\n",
      "('fat', 'False')\n",
      "('burner', 'False')\n",
      "('to', 'False')\n",
      "('see', 'False')\n",
      "('good', 'False')\n",
      "('results.', 'False')\n",
      "('i', 'False')\n",
      "('want', 'False')\n",
      "('protein', 'False')\n",
      "('without', 'False')\n",
      "('lactose', 'True')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('whey', 'False')\n",
      "('proteine', 'False')\n",
      "('with', 'False')\n",
      "('not', 'False')\n",
      "('soy', 'True')\n",
      "('in', 'True')\n",
      "('it!', 'True')\n",
      "('Hi,', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('whey', 'False')\n",
      "('protein', 'False')\n",
      "('with', 'False')\n",
      "('not', 'False')\n",
      "('soy,', 'True')\n",
      "('does', 'False')\n",
      "('it', 'False')\n",
      "('even', 'False')\n",
      "('exist?', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('supplement', 'False')\n",
      "('to', 'False')\n",
      "('help', 'False')\n",
      "('me', 'False')\n",
      "('get', 'False')\n",
      "('back', 'False')\n",
      "('into', 'False')\n",
      "('ketosis', 'False')\n",
      "(',', 'False')\n",
      "('but', 'False')\n",
      "('not', 'False')\n",
      "('a', 'True')\n",
      "('pill.', 'True')\n",
      "('Something', 'False')\n",
      "('I', 'False')\n",
      "('can', 'False')\n",
      "('mix', 'False')\n",
      "('in', 'False')\n",
      "('my', 'False')\n",
      "('water.', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('testosterone', 'False')\n",
      "('supplment', 'False')\n",
      "('and', 'False')\n",
      "('I', 'False')\n",
      "('have', 'False')\n",
      "('no', 'False')\n",
      "('idea', 'True')\n",
      "('which', 'True')\n",
      "('one', 'True')\n",
      "('to', 'True')\n",
      "('buy', 'True')\n",
      "('Hi,', 'False')\n",
      "('I', 'False')\n",
      "('would', 'False')\n",
      "('like', 'False')\n",
      "('to', 'False')\n",
      "('have', 'False')\n",
      "('a', 'False')\n",
      "('protein', 'False')\n",
      "('powder', 'False')\n",
      "('without', 'False')\n",
      "('caffeine', 'True')\n",
      "('i', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('very', 'False')\n",
      "('good', 'False')\n",
      "('fat', 'False')\n",
      "('burner', 'False')\n",
      "('thats', 'False')\n",
      "('not', 'False')\n",
      "('too', 'True')\n",
      "('heavy', 'True')\n",
      "('in', 'True')\n",
      "('stimulants.', 'True')\n",
      "('I', 'False')\n",
      "('saw', 'False')\n",
      "('a', 'False')\n",
      "('sweater', 'False')\n",
      "('block', 'False')\n",
      "('with', 'False')\n",
      "('multi', 'False')\n",
      "('colour', 'False')\n",
      "('yesterday.', 'False')\n",
      "('I', 'False')\n",
      "('wish', 'False')\n",
      "('to', 'False')\n",
      "('order', 'False')\n",
      "('and', 'False')\n",
      "('now', 'False')\n",
      "(\"can't\", 'False')\n",
      "('find..', 'True')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('polo', 'False')\n",
      "('shirt', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('logo', 'True')\n",
      "('on', 'True')\n",
      "('it.', 'True')\n",
      "('Hi', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('the', 'False')\n",
      "('toque', 'False')\n",
      "('and', 'False')\n",
      "('neck', 'False')\n",
      "('tube', 'False')\n",
      "('displayed', 'False')\n",
      "('in', 'False')\n",
      "('the', 'False')\n",
      "(\"woman's\", 'False')\n",
      "('ski', 'False')\n",
      "('jacket', 'False')\n",
      "('the', 'False')\n",
      "('jacket', 'False')\n",
      "('color', 'False')\n",
      "('that', 'False')\n",
      "('is', 'False')\n",
      "('light', 'False')\n",
      "('blue', 'False')\n",
      "('and', 'False')\n",
      "('green', 'False')\n",
      "(',', 'False')\n",
      "('the', 'False')\n",
      "('tuque', 'False')\n",
      "('and', 'False')\n",
      "('neck', 'False')\n",
      "('tube', 'False')\n",
      "('is', 'False')\n",
      "('a', 'False')\n",
      "('dusty', 'False')\n",
      "('pink', 'False')\n",
      "('sort', 'False')\n",
      "('of', 'False')\n",
      "('color,', 'False')\n",
      "('I', 'False')\n",
      "(\"can't\", 'False')\n",
      "('find', 'True')\n",
      "('it', 'True')\n",
      "('anywhere', 'True')\n",
      "('on', 'True')\n",
      "('sight', 'True')\n",
      "('i', 'False')\n",
      "('see', 'True')\n",
      "('simiar', 'True')\n",
      "('items', 'True')\n",
      "('but', 'False')\n",
      "('want', 'False')\n",
      "('a', 'False')\n",
      "('matching', 'False')\n",
      "('set', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('bomber', 'False')\n",
      "('style', 'False')\n",
      "('jacket', 'False')\n",
      "('2', 'False')\n",
      "('XS', 'False')\n",
      "('no', 'False')\n",
      "('hoody', 'True')\n",
      "(',', 'False')\n",
      "('and', 'False')\n",
      "('black', 'False')\n",
      "(\"Women's\", 'False')\n",
      "('pyjama', 'False')\n",
      "('pants', 'False')\n",
      "('without', 'False')\n",
      "('waistband', 'False')\n",
      "('Good', 'False')\n",
      "('morning', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('puffer', 'False')\n",
      "('vest', 'False')\n",
      "('three-quarter', 'False')\n",
      "('length', 'False')\n",
      "(\"I've\", 'False')\n",
      "('seen', 'False')\n",
      "('them', 'False')\n",
      "('On', 'False')\n",
      "('the', 'False')\n",
      "('website', 'False')\n",
      "('but', 'False')\n",
      "('no', 'False')\n",
      "('longer', 'True')\n",
      "('there', 'True')\n",
      "('Good', 'False')\n",
      "('morning,', 'False')\n",
      "('I', 'False')\n",
      "('would', 'False')\n",
      "('like', 'False')\n",
      "('to', 'False')\n",
      "('buy', 'False')\n",
      "('the', 'False')\n",
      "('product', 'False')\n",
      "('below,', 'False')\n",
      "('size', 'False')\n",
      "('M:', 'False')\n",
      "('How', 'False')\n",
      "('can', 'False')\n",
      "('I', 'False')\n",
      "('proceed', 'False')\n",
      "('with', 'False')\n",
      "('this', 'False')\n",
      "('purchase?', 'False')\n",
      "('It', 'False')\n",
      "(\"doesn't\", 'False')\n",
      "('seem', 'True')\n",
      "('to', 'True')\n",
      "('be', 'True')\n",
      "('available', 'True')\n",
      "('at', 'True')\n",
      "('the', 'True')\n",
      "('moment', 'True')\n",
      "('Want', 'False')\n",
      "('to', 'False')\n",
      "('order', 'False')\n",
      "(\"Women's\", 'False')\n",
      "('warm', 'False')\n",
      "('waterproof', 'False')\n",
      "('snow', 'False')\n",
      "('boots', 'False')\n",
      "('in', 'False')\n",
      "('size', 'False')\n",
      "('8', 'False')\n",
      "('.', 'False')\n",
      "(\"Doesn't\", 'False')\n",
      "('say', 'True')\n",
      "('out', 'True')\n",
      "('of', 'True')\n",
      "('stock', 'True')\n",
      "('but', 'True')\n",
      "(\"can't\", 'False')\n",
      "('put', 'True')\n",
      "('order', 'True')\n",
      "('in.', 'True')\n",
      "('Please', 'False')\n",
      "('advise.', 'False')\n",
      "('Hi,', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('interested', 'False')\n",
      "('in', 'False')\n",
      "('the', 'False')\n",
      "(\"women's\", 'False')\n",
      "('waterproof', 'False')\n",
      "('mountain', 'False')\n",
      "('walking', 'False')\n",
      "('jacket', 'False')\n",
      "('in', 'False')\n",
      "('green', 'False')\n",
      "('but', 'False')\n",
      "('the', 'False')\n",
      "('website', 'False')\n",
      "('only', 'False')\n",
      "('gives', 'False')\n",
      "('the', 'False')\n",
      "('option', 'False')\n",
      "('for', 'False')\n",
      "('size', 'False')\n",
      "('XS', 'False')\n",
      "('and', 'False')\n",
      "('does', 'False')\n",
      "('not', 'False')\n",
      "('allow', 'True')\n",
      "('to', 'True')\n",
      "('request', 'True')\n",
      "('a', 'True')\n",
      "('notification', 'True')\n",
      "('Hi', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('to', 'False')\n",
      "('buy', 'False')\n",
      "('this', 'False')\n",
      "('but', 'False')\n",
      "('I', 'False')\n",
      "('cannot', 'False')\n",
      "('find', 'True')\n",
      "('an', 'True')\n",
      "('22', 'True')\n",
      "('mm', 'True')\n",
      "('nozzle', 'True')\n",
      "('pump', 'True')\n",
      "('anywhere,', 'True')\n",
      "('do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('one', 'False')\n",
      "('on', 'False')\n",
      "('your', 'False')\n",
      "('site', 'False')\n",
      "('or', 'False')\n",
      "('know', 'False')\n",
      "('where', 'False')\n",
      "('I', 'False')\n",
      "('can', 'False')\n",
      "('get', 'False')\n",
      "('one?', 'False')\n",
      "('Thanks', 'False')\n",
      "('Pool', 'False')\n",
      "('cue', 'False')\n",
      "('cases', 'False')\n",
      "('not', 'False')\n",
      "('pool', 'True')\n",
      "('cues', 'False')\n",
      "('Looking', 'False')\n",
      "('to', 'False')\n",
      "('buy', 'False')\n",
      "('hiking', 'False')\n",
      "('trousers', 'False')\n",
      "('but', 'False')\n",
      "(\"don't\", 'False')\n",
      "('understand', 'True')\n",
      "('sizes.', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('38in', 'False')\n",
      "('waist', 'False')\n",
      "('and', 'False')\n",
      "('29in', 'False')\n",
      "('leg.', 'False')\n",
      "('Looking', 'False')\n",
      "('to', 'False')\n",
      "('buy', 'False')\n",
      "('trekking', 'False')\n",
      "('trousers', 'False')\n",
      "('what', 'False')\n",
      "('size', 'False')\n",
      "('do', 'False')\n",
      "('I', 'False')\n",
      "('need', 'False')\n",
      "('is', 'False')\n",
      "('it', 'False')\n",
      "('possible', 'False')\n",
      "('to', 'False')\n",
      "('order', 'False')\n",
      "('a', 'False')\n",
      "('bathroom', 'False')\n",
      "('vanity', 'False')\n",
      "('without', 'False')\n",
      "('the', 'True')\n",
      "('countertop?', 'True')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('shower', 'False')\n",
      "('unit', 'False')\n",
      "('including', 'False')\n",
      "('walls', 'False')\n",
      "('bae', 'False')\n",
      "('and', 'False')\n",
      "('glass', 'False')\n",
      "('enclosure', 'False')\n",
      "('but', 'False')\n",
      "('the', 'False')\n",
      "('whole', 'False')\n",
      "('unit', 'False')\n",
      "('cannot', 'False')\n",
      "('be', 'True')\n",
      "('higher', 'True')\n",
      "('than', 'True')\n",
      "('75', 'True')\n",
      "('inches', 'True')\n",
      "('Hi', 'False')\n",
      "('i', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('10\"', 'False')\n",
      "('rough', 'False')\n",
      "('in', 'False')\n",
      "('toilet', 'False')\n",
      "('asap,', 'False')\n",
      "(\"i'm\", 'False')\n",
      "('not', 'False')\n",
      "('sure', 'True')\n",
      "('if', 'True')\n",
      "('you', 'True')\n",
      "('have', 'True')\n",
      "('it', 'True')\n",
      "('in', 'True')\n",
      "('stock.', 'True')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('want', 'True')\n",
      "('the', 'True')\n",
      "('screw', 'True')\n",
      "('less', 'True')\n",
      "('Can', 'False')\n",
      "('the', 'False')\n",
      "('shower', 'False')\n",
      "('be', 'False')\n",
      "('sold', 'False')\n",
      "('without', 'False')\n",
      "('the', 'True')\n",
      "('walls?', 'True')\n",
      "('You', 'False')\n",
      "(\"don't\", 'False')\n",
      "('sell', 'True')\n",
      "('any', 'True')\n",
      "('72\"', 'True')\n",
      "('wide', 'True')\n",
      "('vanities?', 'True')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('shower', 'False')\n",
      "('system', 'False')\n",
      "('with', 'False')\n",
      "('tub', 'False')\n",
      "('faucet', 'False')\n",
      "('altough', 'False')\n",
      "('no', 'False')\n",
      "('tub', 'True')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('bathroom', 'False')\n",
      "('vanity', 'False')\n",
      "('&', 'False')\n",
      "('sink', 'False')\n",
      "('no', 'False')\n",
      "('more', 'True')\n",
      "('than', 'True')\n",
      "('16\"', 'False')\n",
      "('deep', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('48', 'False')\n",
      "('inches', 'False')\n",
      "('floor', 'False')\n",
      "('cabinet', 'False')\n",
      "('single', 'False')\n",
      "('sink,', 'False')\n",
      "('but', 'False')\n",
      "('no', 'False')\n",
      "('couter', 'True')\n",
      "('top', 'False')\n",
      "('Can', 'False')\n",
      "('I', 'False')\n",
      "('purchase', 'False')\n",
      "('shower', 'False')\n",
      "('doors', 'False')\n",
      "('and', 'False')\n",
      "('not', 'False')\n",
      "('the', 'True')\n",
      "('entire', 'True')\n",
      "('shower', 'True')\n",
      "('kit?', 'True')\n",
      "('Medicine', 'False')\n",
      "('cabinets', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('mirror', 'True')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('55', 'False')\n",
      "('inch', 'False')\n",
      "('vanity', 'False')\n",
      "('top,', 'False')\n",
      "('which', 'False')\n",
      "('is', 'False')\n",
      "('not', 'False')\n",
      "('a', 'True')\n",
      "('regular', 'True')\n",
      "('size.', 'True')\n",
      "('Is', 'False')\n",
      "('there', 'False')\n",
      "('a', 'False')\n",
      "('way', 'False')\n",
      "('to', 'False')\n",
      "('have', 'False')\n",
      "('this', 'False')\n",
      "('size?', 'False')\n",
      "('I', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('42\"', 'False')\n",
      "('kitchen', 'False')\n",
      "('island.', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('any?', 'False')\n",
      "('I', 'False')\n",
      "(\"can't\", 'False')\n",
      "('find', 'True')\n",
      "('them', 'True')\n",
      "('on', 'True')\n",
      "('the', 'True')\n",
      "('website.', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('black', 'False')\n",
      "('glass', 'False')\n",
      "('shower', 'False')\n",
      "('tile.', 'False')\n",
      "('It', 'False')\n",
      "('does', 'False')\n",
      "('not', 'False')\n",
      "('need', 'True')\n",
      "('to', 'True')\n",
      "('be', 'True')\n",
      "('a', 'True')\n",
      "('solid', 'True')\n",
      "('black,', 'True')\n",
      "('can', 'False')\n",
      "('have', 'False')\n",
      "('accents', 'False')\n",
      "('of', 'False')\n",
      "('clear', 'False')\n",
      "('or', 'False')\n",
      "('silver', 'False')\n",
      "('glass', 'False')\n",
      "('tones', 'False')\n",
      "('Medicine', 'False')\n",
      "('cabinet', 'False')\n",
      "('with', 'False')\n",
      "('mirror', 'False')\n",
      "('and', 'False')\n",
      "('no', 'False')\n",
      "('lights', 'True')\n",
      "('We', 'False')\n",
      "('are', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('72', 'False')\n",
      "('inch', 'False')\n",
      "('soaker', 'False')\n",
      "('tub,', 'False')\n",
      "('no', 'False')\n",
      "('jets.', 'True')\n",
      "('can', 'False')\n",
      "('I', 'False')\n",
      "('order', 'False')\n",
      "('just', 'False')\n",
      "('the', 'False')\n",
      "('top', 'False')\n",
      "('and', 'False')\n",
      "('not', 'False')\n",
      "('the', 'True')\n",
      "('cabinet?', 'True')\n",
      "('barbeque', 'False')\n",
      "('without', 'False')\n",
      "('charcoal', 'False')\n",
      "('Hi', 'False')\n",
      "('there,', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('interested', 'False')\n",
      "('in', 'False')\n",
      "('a', 'False')\n",
      "('vanity.', 'False')\n",
      "('Am', 'False')\n",
      "('I', 'False')\n",
      "('able', 'False')\n",
      "('to', 'False')\n",
      "('purchase', 'False')\n",
      "('without', 'False')\n",
      "('the', 'False')\n",
      "('sink', 'True')\n",
      "('top?', 'True')\n",
      "('Can', 'False')\n",
      "('I', 'False')\n",
      "('order', 'False')\n",
      "('this', 'False')\n",
      "('vessel', 'False')\n",
      "('sink', 'False')\n",
      "('without', 'False')\n",
      "('the', 'True')\n",
      "('attached', 'True')\n",
      "('faucet', 'True')\n",
      "('?', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('30\"', 'False')\n",
      "('cabinet', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('top', 'True')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('vanity', 'False')\n",
      "('but', 'False')\n",
      "('sink', 'False')\n",
      "('must', 'False')\n",
      "('have', 'False')\n",
      "('no', 'False')\n",
      "('holes.', 'True')\n",
      "('Faucet', 'False')\n",
      "('in', 'False')\n",
      "('on', 'False')\n",
      "('wall', 'False')\n",
      "('already', 'False')\n",
      "('Hi.', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('36\"', 'False')\n",
      "('vanity', 'False')\n",
      "('wall', 'False')\n",
      "('mounted', 'False')\n",
      "('black', 'False')\n",
      "('or', 'False')\n",
      "('white.', 'False')\n",
      "('With', 'False')\n",
      "('towel', 'False')\n",
      "('storage', 'False')\n",
      "('but', 'False')\n",
      "('no', 'False')\n",
      "('sinc', 'True')\n",
      "('I', 'False')\n",
      "('want', 'False')\n",
      "('just', 'False')\n",
      "('this', 'False')\n",
      "('cabinet', 'False')\n",
      "('without', 'False')\n",
      "('the', 'True')\n",
      "('top', 'True')\n",
      "('as', 'False')\n",
      "('i', 'False')\n",
      "('want', 'False')\n",
      "('top', 'False')\n",
      "('mounted', 'False')\n",
      "('basins', 'False')\n",
      "('on', 'False')\n",
      "('a', 'False')\n",
      "('surface', 'False')\n",
      "('matching', 'False')\n",
      "('my', 'False')\n",
      "('kitchen', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('pivot', 'False')\n",
      "('shower', 'False')\n",
      "('door', 'False')\n",
      "('in', 'False')\n",
      "('black', 'False')\n",
      "('to', 'False')\n",
      "('fit', 'False')\n",
      "('a', 'False')\n",
      "('33', 'False')\n",
      "('inch', 'False')\n",
      "('opening', 'False')\n",
      "('preferably', 'False')\n",
      "('but', 'False')\n",
      "('not', 'False')\n",
      "('necessarily.', 'True')\n",
      "('bathtub', 'False')\n",
      "('without', 'False')\n",
      "('faucet?', 'False')\n",
      "('Can', 'False')\n",
      "('you', 'False')\n",
      "('order', 'False')\n",
      "('the', 'False')\n",
      "('59\"', 'False')\n",
      "('bathrub', 'False')\n",
      "('without', 'False')\n",
      "('the', 'True')\n",
      "('faucet?', 'True')\n",
      "('I', 'False')\n",
      "('want', 'False')\n",
      "('Grey', 'False')\n",
      "('toilet', 'False')\n",
      "('not', 'False')\n",
      "('assessceries', 'True')\n",
      "('I', 'False')\n",
      "('cannot', 'False')\n",
      "('seem', 'True')\n",
      "('to', 'True')\n",
      "('sort', 'True')\n",
      "('by', 'True')\n",
      "('colour.', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('cream', 'False')\n",
      "('38\"', 'False')\n",
      "('corner', 'False')\n",
      "('shower', 'False')\n",
      "('stall', 'False')\n",
      "('do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('60', 'False')\n",
      "('Inch', 'False')\n",
      "('kitchen', 'False')\n",
      "('island', 'False')\n",
      "('with', 'False')\n",
      "('quartz', 'False')\n",
      "('top', 'False')\n",
      "('with', 'False')\n",
      "('no', 'False')\n",
      "('seatings', 'True')\n",
      "('Frameless', 'False')\n",
      "('beveled', 'False')\n",
      "('mirror', 'False')\n",
      "('no', 'False')\n",
      "('more', 'True')\n",
      "('than', 'True')\n",
      "('29\"x29\"', 'True')\n",
      "('Bath', 'False')\n",
      "('tub', 'False')\n",
      "('without', 'False')\n",
      "('texture', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('bathroom', 'False')\n",
      "('cabinet', 'False')\n",
      "('without', 'False')\n",
      "('top', 'True')\n",
      "('60', 'True')\n",
      "('inches', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('medicine', 'False')\n",
      "('cabinet', 'False')\n",
      "('with', 'False')\n",
      "('mirror', 'False')\n",
      "('front', 'False')\n",
      "('not', 'False')\n",
      "('Recessed', 'True')\n",
      "('that', 'True')\n",
      "('would', 'True')\n",
      "('fit', 'True')\n",
      "('50', 'True')\n",
      "('inch', 'True')\n",
      "('wide', 'True')\n",
      "('39', 'False')\n",
      "('inch', 'False')\n",
      "('tall', 'False')\n",
      "('the', 'False')\n",
      "('best', 'False')\n",
      "('I', 'False')\n",
      "('need', 'False')\n",
      "('a', 'False')\n",
      "('60\"', 'False')\n",
      "('vanity', 'False')\n",
      "('with', 'False')\n",
      "('a', 'False')\n",
      "('sink', 'False')\n",
      "(\"that's\", 'False')\n",
      "('offset', 'False')\n",
      "('to', 'False')\n",
      "('the', 'False')\n",
      "('right', 'False')\n",
      "('-', 'False')\n",
      "('not', 'False')\n",
      "('centred', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('37', 'False')\n",
      "('inch', 'False')\n",
      "('bathroom', 'False')\n",
      "('cabinet', 'False')\n",
      "('without', 'False')\n",
      "('a', 'True')\n",
      "('top', 'True')\n",
      "('or', 'True')\n",
      "('sink', 'True')\n",
      "('because', 'False')\n",
      "('I', 'False')\n",
      "('have', 'False')\n",
      "('one.', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('anything', 'False')\n",
      "('in', 'False')\n",
      "('stock?', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('mirror', 'False')\n",
      "('without', 'False')\n",
      "('a', 'True')\n",
      "('fram', 'True')\n",
      "('40', 'True')\n",
      "('inches', 'True')\n",
      "('x', 'True')\n",
      "('60', 'True')\n",
      "('inches', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('kitchen', 'False')\n",
      "('faucet', 'False')\n",
      "('in', 'False')\n",
      "('Stainless', 'False')\n",
      "('Steel.', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('in', 'False')\n",
      "('stock', 'False')\n",
      "('na', 'False')\n",
      "('did', 'False')\n",
      "('not', 'False')\n",
      "('what', 'True')\n",
      "('would', 'True')\n",
      "('be', 'True')\n",
      "('turn', 'True')\n",
      "('around', 'True')\n",
      "('time', 'True')\n",
      "('and', 'True')\n",
      "('pricing.', 'True')\n",
      "('Thanks', 'False')\n",
      "('Hi', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('24', 'False')\n",
      "('inch', 'False')\n",
      "('vanity', 'False')\n",
      "('top', 'False')\n",
      "('and', 'False')\n",
      "('sink,', 'False')\n",
      "('no', 'False')\n",
      "('base', 'True')\n",
      "('Bathroom', 'False')\n",
      "('vanities', 'False')\n",
      "('no', 'False')\n",
      "('countertop', 'True')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('want', 'True')\n",
      "('double', 'True')\n",
      "('sink,', 'True')\n",
      "('I', 'False')\n",
      "('want', 'False')\n",
      "('a', 'False')\n",
      "('rectangle', 'False')\n",
      "('sink', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('30', 'False')\n",
      "('inch', 'False')\n",
      "('bathroom', 'False')\n",
      "('vanity', 'False')\n",
      "('not', 'False')\n",
      "('55\"', 'True')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('30', 'False')\n",
      "('inch', 'False')\n",
      "('bathroom', 'False')\n",
      "('shelf', 'False')\n",
      "('not', 'False')\n",
      "('wall', 'True')\n",
      "('mounted', 'True')\n",
      "('Wall', 'False')\n",
      "('mount', 'False')\n",
      "('rectangular', 'False')\n",
      "('sink', 'False')\n",
      "('without', 'False')\n",
      "('a', 'True')\n",
      "('faucet', 'True')\n",
      "('hole', 'False')\n",
      "('Grey', 'False')\n",
      "('toilet', 'False')\n",
      "('not', 'False')\n",
      "('toilet', 'True')\n",
      "('brush', 'False')\n",
      "('Good', 'False')\n",
      "('morning.', 'False')\n",
      "('We', 'False')\n",
      "('are', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('chrome', 'False')\n",
      "('shower', 'False')\n",
      "('head', 'False')\n",
      "('with', 'False')\n",
      "('high', 'False')\n",
      "('pressure', 'False')\n",
      "('-', 'False')\n",
      "('simple', 'False')\n",
      "('no', 'False')\n",
      "('bells', 'True')\n",
      "('and', 'True')\n",
      "('whistles', 'False')\n",
      "('just', 'False')\n",
      "('good', 'False')\n",
      "('pressure', 'False')\n",
      "('can', 'False')\n",
      "('you', 'False')\n",
      "('help', 'False')\n",
      "('me', 'False')\n",
      "('find', 'False')\n",
      "('a', 'False')\n",
      "('pharmacy', 'False')\n",
      "('without', 'False')\n",
      "('a', 'True')\n",
      "('mirror', 'True')\n",
      "('18-20\"', 'False')\n",
      "('wide?', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('double', 'False')\n",
      "('sink', 'False')\n",
      "('in', 'False')\n",
      "('black', 'False')\n",
      "('that', 'False')\n",
      "('is', 'False')\n",
      "('no', 'False')\n",
      "('more', 'True')\n",
      "('than', 'True')\n",
      "('23\"', 'True')\n",
      "('wide.', 'True')\n",
      "('Does', 'False')\n",
      "('this', 'False')\n",
      "('exist?', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('toilet', 'False')\n",
      "('seat', 'False')\n",
      "('without', 'False')\n",
      "('undermounted', 'True')\n",
      "('hinges', 'True')\n",
      "('for', 'True')\n",
      "('a', 'True')\n",
      "('one', 'True')\n",
      "('piece', 'True')\n",
      "('toilet', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('mirror', 'False')\n",
      "('medicine', 'False')\n",
      "('cabinet', 'False')\n",
      "('without', 'False')\n",
      "('led', 'False')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('have', 'False')\n",
      "('shower', 'False')\n",
      "('panels', 'False')\n",
      "('that', 'False')\n",
      "(\"aren't\", 'False')\n",
      "('see', 'True')\n",
      "('through?', 'True')\n",
      "('Like', 'False')\n",
      "('frosted', 'False')\n",
      "('glass', 'False')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('need', 'True')\n",
      "('a', 'True')\n",
      "('vanity', 'True')\n",
      "('just', 'True')\n",
      "('the', 'True')\n",
      "('quartz', 'True')\n",
      "('top', 'True')\n",
      "('with', 'True')\n",
      "('built', 'True')\n",
      "('in', 'True')\n",
      "('sink', 'True')\n",
      "('Hi,', 'False')\n",
      "('I', 'False')\n",
      "('was', 'False')\n",
      "('looking', 'False')\n",
      "('a', 'False')\n",
      "('free', 'False')\n",
      "('standing', 'False')\n",
      "('tub', 'False')\n",
      "('yesterday', 'False')\n",
      "('for', 'False')\n",
      "('$650', 'False')\n",
      "(',', 'False')\n",
      "('it', 'False')\n",
      "('was', 'False')\n",
      "('on', 'False')\n",
      "('for', 'False')\n",
      "('50%', 'False')\n",
      "('off.', 'False')\n",
      "('I', 'False')\n",
      "(\"don't\", 'False')\n",
      "('see', 'True')\n",
      "('it', 'True')\n",
      "('now,', 'True')\n",
      "('is', 'False')\n",
      "('it', 'False')\n",
      "('still', 'False')\n",
      "('on', 'False')\n",
      "('sale', 'False')\n",
      "('?', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('large', 'False')\n",
      "('free', 'False')\n",
      "('standing', 'False')\n",
      "('tub...', 'False')\n",
      "('not', 'False')\n",
      "('acrylic', 'True')\n",
      "('or', 'True')\n",
      "('fiberglass', 'True')\n",
      "('i', 'False')\n",
      "(\"don't\", 'False')\n",
      "('want', 'True')\n",
      "('a', 'True')\n",
      "('complete', 'True')\n",
      "('vanity', 'True')\n",
      "('just', 'True')\n",
      "('the', 'True')\n",
      "('top', 'True')\n",
      "('Hi', 'False')\n",
      "('..', 'False')\n",
      "('never', 'False')\n",
      "('been', 'True')\n",
      "('to', 'True')\n",
      "('your', 'True')\n",
      "('store', 'True')\n",
      "(',looking', 'True')\n",
      "('for', 'True')\n",
      "('vinyl', 'True')\n",
      "('wardrobes', 'True')\n",
      "('do', 'False')\n",
      "('not', 'False')\n",
      "('know', 'True')\n",
      "('if', 'True')\n",
      "('you', 'True')\n",
      "('carry', 'True')\n",
      "('those', 'True')\n",
      "('..', 'False')\n",
      "('thanks', 'False')\n",
      "('Thank', 'False')\n",
      "('you', 'False')\n",
      "('very', 'False')\n",
      "('much', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('shower', 'False')\n",
      "('stall', 'False')\n",
      "('kit', 'False')\n",
      "('that', 'False')\n",
      "('is', 'False')\n",
      "('not', 'False')\n",
      "('priced', 'True')\n",
      "('to', 'True')\n",
      "('high', 'True')\n",
      "(\"it's\", 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('basement', 'False')\n",
      "('t-shirt', 'False')\n",
      "('without', 'False')\n",
      "('logo', 'False')\n",
      "('Shower', 'False')\n",
      "('door', 'False')\n",
      "('no', 'False')\n",
      "('side', 'True')\n",
      "('panels', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('heated', 'False')\n",
      "('air', 'False')\n",
      "('and', 'False')\n",
      "('water', 'False')\n",
      "('jetted', 'False')\n",
      "('tub.', 'False')\n",
      "('bathub', 'False')\n",
      "('with', 'False')\n",
      "('jets', 'False')\n",
      "('Hello,', 'False')\n",
      "('what', 'False')\n",
      "('is', 'False')\n",
      "('the', 'False')\n",
      "('biggest', 'False')\n",
      "('blade', 'False')\n",
      "('on', 'False')\n",
      "('a', 'False')\n",
      "('shower', 'False')\n",
      "('squeegee', 'False')\n",
      "('that', 'False')\n",
      "('you', 'False')\n",
      "('carry??', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('bathtub', 'False')\n",
      "('left', 'False')\n",
      "('hand', 'False')\n",
      "('drain', 'False')\n",
      "('but', 'False')\n",
      "('square', 'False')\n",
      "('not', 'False')\n",
      "('oval', 'True')\n",
      "('Do', 'False')\n",
      "('you', 'False')\n",
      "('sell', 'False')\n",
      "('a', 'False')\n",
      "('tub', 'False')\n",
      "('shower', 'False')\n",
      "('faucet', 'False')\n",
      "('set', 'False')\n",
      "('that', 'False')\n",
      "('does', 'False')\n",
      "('not', 'False')\n",
      "('have', 'True')\n",
      "('the', 'True')\n",
      "('anti', 'True')\n",
      "('scald', 'True')\n",
      "('feature?', 'True')\n",
      "('What', 'False')\n",
      "('rectangular', 'False')\n",
      "('shower', 'False')\n",
      "('units', 'False')\n",
      "('are', 'False')\n",
      "('available?', 'False')\n",
      "('I', 'False')\n",
      "('am', 'False')\n",
      "('looking', 'False')\n",
      "('for', 'False')\n",
      "('a', 'False')\n",
      "('35', 'False')\n",
      "('inch', 'False')\n",
      "('bathroom', 'False')\n",
      "('sink', 'False')\n",
      "('countertop', 'False')\n",
      "('with', 'False')\n",
      "('sink', 'False')\n",
      "(\"I'm\", 'False')\n",
      "('looking', 'False')\n",
      "('f', 'False')\n",
      "('or', 'False')\n",
      "('a', 'False')\n",
      "('Black', 'False')\n",
      "('Matte', 'False')\n",
      "('bathtub', 'False')\n",
      "('double', 'False')\n",
      "('sliding', 'False')\n",
      "('door', 'False')\n",
      "('Need', 'False')\n",
      "('a', 'False')\n",
      "('27', 'False')\n",
      "('inch', 'False')\n",
      "('frameless', 'False')\n",
      "('shower', 'False')\n",
      "('door', 'False')\n",
      "('Looking', 'False')\n",
      "('for', 'False')\n",
      "('30', 'False')\n",
      "('inch', 'False')\n",
      "('white', 'False')\n",
      "('desk', 'False')\n",
      "('set', 'False')\n"
     ]
    }
   ],
   "source": [
    "for i in zip(tokens,predictions):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
